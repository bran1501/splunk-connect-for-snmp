{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Splunk Connect for SNMP \u00b6 Splunk welcomes your experimentation and feedback. Let your account team knows you are testing Splunk Connect for SNMP. Splunk Connect for SNMP is an edge-deployed, containerized, and highly available solution for collecting SNMP data for Splunk Enterprise, Splunk Enterprise Cloud and Splunk Infrastructure Monitoring.","title":"Home"},{"location":"#splunk-connect-for-snmp","text":"Splunk welcomes your experimentation and feedback. Let your account team knows you are testing Splunk Connect for SNMP. Splunk Connect for SNMP is an edge-deployed, containerized, and highly available solution for collecting SNMP data for Splunk Enterprise, Splunk Enterprise Cloud and Splunk Infrastructure Monitoring.","title":"Splunk Connect for SNMP"},{"location":"bestpractices/","text":"Debug Splunk Connect for SNMP \u00b6 Pieces of Advice \u00b6 Check when SNMP WALK was executed last time for device \u00b6 Configure Splunk OpenTelemetry Collector for Kubernetes Go to your Splunk and execute search: index=\"em_logs\" \"Sending due task\" \"sc4snmp;<IP_ADDRESS>;walk\" and replace by IP Address which you are interested. Uninstall Splunk Connect for SNMP \u00b6 To uninstall SC4SNMP run the following commands: microk8s helm3 uninstall snmp -n sc4snmp microk8s kubectl delete pvc --all -n sc4snmp Installing Splunk Connect for SNMP on Linux RedHat \u00b6 Installation of RedHat may be blocking ports required by microk8s. Installing microk8s on RedHat required checking if the firewall is not blocking any of required microk8s ports . Issues \u00b6 \u201cEmpty SNMP response message\u201d problem \u00b6 In case you see the following line in worker\u2019s logs: [ 2022 - 01 - 04 11 : 44 : 22 , 553 : INFO / ForkPoolWorker - 1 ] Task splunk_connect_for_snmp . snmp . tasks . walk [ 8 e62fc62 - 569 c - 473 f - a765 - ff92577774e5 ] retry : Retry in 3489 s : SnmpActionError ( ' An error of SNMP isWalk=True for a host 192.168.10.20 occurred: Empty SNMP response message ' ) that causes infinite retry of walk operation, add worker.ignoreEmptyVarbinds parameter to values.yaml and set it to true. An example configuration for a worker in values.yaml is: worker : ignoreEmptyVarbinds : true \u201cOID not increasing\u201d problem \u00b6 In case you see the following line in worker\u2019s logs: [ 2022 - 01 - 04 11 : 44 : 22 , 553 : INFO / ForkPoolWorker - 1 ] Task splunk_connect_for_snmp . snmp . tasks . walk [ 8 e62fc62 - 569 c - 473 f - a765 - ff92577774e5 ] retry : Retry in 3489 s : SnmpActionError ( ' An error of SNMP isWalk=True for a host 192.168.10.20 occurred: OID not increasing ' ) that causes infinite retry of walk operation, add worker.ignoreNotIncreasingOid array to values.yaml and fill with the addresses of hosts where the problem appears. An example configuration for a worker in values.yaml is: worker : ignoreNotIncreasingOid : - \"127.0.0.1:164\" - \"127.0.0.6\" If you put only IP address (ex. 127.0.0.1 ), then errors will be ignored for all of its devices (like 127.0.0.1:161 , 127.0.0.1:163 \u2026). If you put IP address and host structured as {host}:{port} that means the error will be ignored only for this device. Walking a device takes much time \u00b6 If you would like to limit the scope of the walk, you should set one of the profiles in the inventory to point to the profile definition of type walk scheduler : profiles : | small_walk: condition: type: \"walk\" varBinds: - ['UDP-MIB'] Such profile should be placed in the profiles section of inventory definition. It will be executed with the frequency defined in walk_interval. In case of multiple profiles of type walk will be placed in profiles, the last one will be used. poller : inventory : | address,port,version,community,secret,securityEngine,walk_interval,profiles,SmartProfiles,delete 10.202.4.202,,2c,public,,,2000,small_walk,, NOTE: When small walk is configured, you can set up polling only of OIDs belonging to walk profile varBinds. Additionally, there are two MIB families that are enabled by default (we need them to create state of the device in the database and poll base profiles): IF-MIB and SNMPv2-MIB . For example, if you\u2019ve decided to use small_walk from the example above, you\u2019ll be able to poll only UDP-MIB , IF-MIB and SNMPv2-MIB OIDs.","title":"Troubleshooting"},{"location":"bestpractices/#debug-splunk-connect-for-snmp","text":"","title":"Debug Splunk Connect for SNMP"},{"location":"bestpractices/#pieces-of-advice","text":"","title":"Pieces of Advice"},{"location":"bestpractices/#check-when-snmp-walk-was-executed-last-time-for-device","text":"Configure Splunk OpenTelemetry Collector for Kubernetes Go to your Splunk and execute search: index=\"em_logs\" \"Sending due task\" \"sc4snmp;<IP_ADDRESS>;walk\" and replace by IP Address which you are interested.","title":"Check when SNMP WALK was executed last time for device"},{"location":"bestpractices/#uninstall-splunk-connect-for-snmp","text":"To uninstall SC4SNMP run the following commands: microk8s helm3 uninstall snmp -n sc4snmp microk8s kubectl delete pvc --all -n sc4snmp","title":"Uninstall Splunk Connect for SNMP"},{"location":"bestpractices/#installing-splunk-connect-for-snmp-on-linux-redhat","text":"Installation of RedHat may be blocking ports required by microk8s. Installing microk8s on RedHat required checking if the firewall is not blocking any of required microk8s ports .","title":"Installing Splunk Connect for SNMP on Linux RedHat"},{"location":"bestpractices/#issues","text":"","title":"Issues"},{"location":"bestpractices/#empty-snmp-response-message-problem","text":"In case you see the following line in worker\u2019s logs: [ 2022 - 01 - 04 11 : 44 : 22 , 553 : INFO / ForkPoolWorker - 1 ] Task splunk_connect_for_snmp . snmp . tasks . walk [ 8 e62fc62 - 569 c - 473 f - a765 - ff92577774e5 ] retry : Retry in 3489 s : SnmpActionError ( ' An error of SNMP isWalk=True for a host 192.168.10.20 occurred: Empty SNMP response message ' ) that causes infinite retry of walk operation, add worker.ignoreEmptyVarbinds parameter to values.yaml and set it to true. An example configuration for a worker in values.yaml is: worker : ignoreEmptyVarbinds : true","title":"\"Empty SNMP response message\" problem"},{"location":"bestpractices/#oid-not-increasing-problem","text":"In case you see the following line in worker\u2019s logs: [ 2022 - 01 - 04 11 : 44 : 22 , 553 : INFO / ForkPoolWorker - 1 ] Task splunk_connect_for_snmp . snmp . tasks . walk [ 8 e62fc62 - 569 c - 473 f - a765 - ff92577774e5 ] retry : Retry in 3489 s : SnmpActionError ( ' An error of SNMP isWalk=True for a host 192.168.10.20 occurred: OID not increasing ' ) that causes infinite retry of walk operation, add worker.ignoreNotIncreasingOid array to values.yaml and fill with the addresses of hosts where the problem appears. An example configuration for a worker in values.yaml is: worker : ignoreNotIncreasingOid : - \"127.0.0.1:164\" - \"127.0.0.6\" If you put only IP address (ex. 127.0.0.1 ), then errors will be ignored for all of its devices (like 127.0.0.1:161 , 127.0.0.1:163 \u2026). If you put IP address and host structured as {host}:{port} that means the error will be ignored only for this device.","title":"\"OID not increasing\" problem"},{"location":"bestpractices/#walking-a-device-takes-much-time","text":"If you would like to limit the scope of the walk, you should set one of the profiles in the inventory to point to the profile definition of type walk scheduler : profiles : | small_walk: condition: type: \"walk\" varBinds: - ['UDP-MIB'] Such profile should be placed in the profiles section of inventory definition. It will be executed with the frequency defined in walk_interval. In case of multiple profiles of type walk will be placed in profiles, the last one will be used. poller : inventory : | address,port,version,community,secret,securityEngine,walk_interval,profiles,SmartProfiles,delete 10.202.4.202,,2c,public,,,2000,small_walk,, NOTE: When small walk is configured, you can set up polling only of OIDs belonging to walk profile varBinds. Additionally, there are two MIB families that are enabled by default (we need them to create state of the device in the database and poll base profiles): IF-MIB and SNMPv2-MIB . For example, if you\u2019ve decided to use small_walk from the example above, you\u2019ll be able to poll only UDP-MIB , IF-MIB and SNMPv2-MIB OIDs.","title":"Walking a device takes much time"},{"location":"ha/","text":"High Availability Considerations \u00b6 The SNMP protocol uses UDP as the transport protocol and is subject to network reliability, as a constraint. Network architecture should be considered when designing for high availability. When using a single node collector ensure automatic recovery from virtual infrastructure i.e. VMware, Openstack, etc. When using a multi-node cluster ensure nodes are not located such that a simple majority of nodes can be lost for example consider row, rack, network, power, storage When determining the placement of clusters the closest location by the number of network hops should be utilized. For \u201cdata center\u201d applications collection should be local to the data center. Consider IP Anycast","title":"High Availability"},{"location":"ha/#high-availability-considerations","text":"The SNMP protocol uses UDP as the transport protocol and is subject to network reliability, as a constraint. Network architecture should be considered when designing for high availability. When using a single node collector ensure automatic recovery from virtual infrastructure i.e. VMware, Openstack, etc. When using a multi-node cluster ensure nodes are not located such that a simple majority of nodes can be lost for example consider row, rack, network, power, storage When determining the placement of clusters the closest location by the number of network hops should be utilized. For \u201cdata center\u201d applications collection should be local to the data center. Consider IP Anycast","title":"High Availability Considerations"},{"location":"mib-request/","text":"MIB submission process \u00b6 To achieve human-readable OIDs, the corresponding MIB files are necessary. They are being stored in one of the components of SC4SNMP - the MIB server. The list of currently available MIBs is here: https://pysnmp.github.io/mibs/index.csv An alternative way to check if the MIB you\u2019re interested in is being served is to check the link: https://pysnmp.github.io/mibs/asn1/@mib@ where @mib@ is the name of MIB (for example IF-MIB ). If the file is downloading, that means the MIB file exists in the mib server. Submit a new MIB file \u00b6 In case you want to add a new MIB file to the MIB server, follow the steps: Create a fork of the https://github.com/pysnmp/mibs repository Put MIB file/s under src/vendor/@vendor_name@ where @vendor_name@ is the name of the MIB file\u2019s vendor (in case there is no directory of vendors you need, create it by yourself) Create a pull request to a main branch Name the pull request the following way: feat: add @vendor_name@ MIB files An alternative way of adding MIBs to the MIB server is to create an issue on https://github.com/pysnmp/mibs repository, attaching the files and information about the vendor.","title":"Request MIB"},{"location":"mib-request/#mib-submission-process","text":"To achieve human-readable OIDs, the corresponding MIB files are necessary. They are being stored in one of the components of SC4SNMP - the MIB server. The list of currently available MIBs is here: https://pysnmp.github.io/mibs/index.csv An alternative way to check if the MIB you\u2019re interested in is being served is to check the link: https://pysnmp.github.io/mibs/asn1/@mib@ where @mib@ is the name of MIB (for example IF-MIB ). If the file is downloading, that means the MIB file exists in the mib server.","title":"MIB submission process"},{"location":"mib-request/#submit-a-new-mib-file","text":"In case you want to add a new MIB file to the MIB server, follow the steps: Create a fork of the https://github.com/pysnmp/mibs repository Put MIB file/s under src/vendor/@vendor_name@ where @vendor_name@ is the name of the MIB file\u2019s vendor (in case there is no directory of vendors you need, create it by yourself) Create a pull request to a main branch Name the pull request the following way: feat: add @vendor_name@ MIB files An alternative way of adding MIBs to the MIB server is to create an issue on https://github.com/pysnmp/mibs repository, attaching the files and information about the vendor.","title":"Submit a new MIB file"},{"location":"planning/","text":"Planning \u00b6 Splunk Connect for SNMP (SC4SNMP) is a solution that allows the customer to \"get\" data from network devices and appliances when a more feature-complete solution, such as the Splunk Universal Forwarder, is not available. Architecture \u00b6 SC4SNMP is deployed using a Kubernetes distribution, typically MicroK8s, that\u2019s designed to be a low-touch experience for integration with sensitive edge network devices. It will typically be deployed in the same network management zone as the monitored devices and separated from Splunk by an existing firewall. Requirements \u00b6 A supported deployment of MicroK8s 16 Core/32 threads x64 architecture server or vm (single instance) 12 GB ram HA Requires 3 or more instances (odd numbers) 8 core/16 thread 16 GB ram 100 GB root mount HTTP access (non-proxy) allowed for the HTTP(s) connection from SC4SNMP to the Splunk destination. Splunk Enterprise/Cloud 8.x and or Splunk Infrastructure Monitoring (SignalFx) Splunk Enterprise/Cloud specific Requirements: Splunk ITSI or Splunk IT Work Ability to create a HEC token Ability to create event and metrics indexes (or use existing) Splunk Infrastructure Monitoring specific requirements: Ability to create or obtain real and token Planning Infrastructure \u00b6 A single installation of Splunk Connect for SNMP (SC4SNMP) on a machine with 16 Core/32 threads x64 and 12 GB ram will be able to handle up to 1300 SNMP TRAPs per sec. A single installation of Splunk Connect for SNMP (SC4SNMP) on a machine with 16 Core/32 threads x64 and 64 GB ram will be able to handle up to 1300 SNMP GETs per sec. When planning infrastructure for Splunk Connect for SNMP, (SC4SNMP) note the limitations highlighted above.","title":"Planning"},{"location":"planning/#planning","text":"Splunk Connect for SNMP (SC4SNMP) is a solution that allows the customer to \"get\" data from network devices and appliances when a more feature-complete solution, such as the Splunk Universal Forwarder, is not available.","title":"Planning"},{"location":"planning/#architecture","text":"SC4SNMP is deployed using a Kubernetes distribution, typically MicroK8s, that\u2019s designed to be a low-touch experience for integration with sensitive edge network devices. It will typically be deployed in the same network management zone as the monitored devices and separated from Splunk by an existing firewall.","title":"Architecture"},{"location":"planning/#requirements","text":"A supported deployment of MicroK8s 16 Core/32 threads x64 architecture server or vm (single instance) 12 GB ram HA Requires 3 or more instances (odd numbers) 8 core/16 thread 16 GB ram 100 GB root mount HTTP access (non-proxy) allowed for the HTTP(s) connection from SC4SNMP to the Splunk destination. Splunk Enterprise/Cloud 8.x and or Splunk Infrastructure Monitoring (SignalFx) Splunk Enterprise/Cloud specific Requirements: Splunk ITSI or Splunk IT Work Ability to create a HEC token Ability to create event and metrics indexes (or use existing) Splunk Infrastructure Monitoring specific requirements: Ability to create or obtain real and token","title":"Requirements"},{"location":"planning/#planning-infrastructure","text":"A single installation of Splunk Connect for SNMP (SC4SNMP) on a machine with 16 Core/32 threads x64 and 12 GB ram will be able to handle up to 1300 SNMP TRAPs per sec. A single installation of Splunk Connect for SNMP (SC4SNMP) on a machine with 16 Core/32 threads x64 and 64 GB ram will be able to handle up to 1300 SNMP GETs per sec. When planning infrastructure for Splunk Connect for SNMP, (SC4SNMP) note the limitations highlighted above.","title":"Planning Infrastructure"},{"location":"releases/","text":"Base Information \u00b6 Known Issues \u00b6 List of open known issues is available under Known issue link Open issues to the product \u00b6 To open issue for Splunk Connect for SNMP go to github SC4SNMP project and open issue. Releases \u00b6 To check Splunk Connect for SNMP releases please visit: SC4SNMP Releases","title":"Releases"},{"location":"releases/#base-information","text":"","title":"Base Information"},{"location":"releases/#known-issues","text":"List of open known issues is available under Known issue link","title":"Known Issues"},{"location":"releases/#open-issues-to-the-product","text":"To open issue for Splunk Connect for SNMP go to github SC4SNMP project and open issue.","title":"Open issues to the product"},{"location":"releases/#releases","text":"To check Splunk Connect for SNMP releases please visit: SC4SNMP Releases","title":"Releases"},{"location":"security/","text":"Security Considerations \u00b6 The SC4SNMP solution implements SNMP in a compatible mode for current and legacy network device gear. SNMP is a protocol widely considered to be risky and requires threat mitigation at the network level. Do not expose SNMP endpoints to untrusted connections such as the internet or general LAN network of a typical enterprise. Do not allow SNMPv1 or SNMPv2 connections to cross a network zone where a man in the middle interception is possible. Be aware many SNMPv3 devices rely on insecure cryptography including DES, MD5, and SHA. Do not presume SNMPv3 devices and connections are secure by default. When possible use SNMPv3 with the most secure protocol options mutually supported. The default IP of each node should be considered a management interface and should be protected from network access by an untrusted device by a hardware or software firewall. When possible the IP allocated for SNMP communication should not be shared by the management interface.","title":"Security"},{"location":"security/#security-considerations","text":"The SC4SNMP solution implements SNMP in a compatible mode for current and legacy network device gear. SNMP is a protocol widely considered to be risky and requires threat mitigation at the network level. Do not expose SNMP endpoints to untrusted connections such as the internet or general LAN network of a typical enterprise. Do not allow SNMPv1 or SNMPv2 connections to cross a network zone where a man in the middle interception is possible. Be aware many SNMPv3 devices rely on insecure cryptography including DES, MD5, and SHA. Do not presume SNMPv3 devices and connections are secure by default. When possible use SNMPv3 with the most secure protocol options mutually supported. The default IP of each node should be considered a management interface and should be protected from network access by an untrusted device by a hardware or software firewall. When possible the IP allocated for SNMP communication should not be shared by the management interface.","title":"Security Considerations"},{"location":"configuration/deployment-configuration/","text":"Deployment Configuration \u00b6 values.yaml are the main point of SC4SNMP management. The most important variables are already there from the very beginning after executing: microk8s helm3 inspect values splunk - connect - for - snmp / splunk - connect - for - snmp > values . yaml The whole file is divided into the following components: scheduler - more detail scheduler configuration worker - more detail worker configuration poller - more detail poller configuration sim - more detail sim configuration traps - more detail trap configuration mongodb - more detail mongo configuration rabbitmq - more detail rabbitmq configuration Shared values \u00b6 All of the components have the resources field for adjusting memory resources: resources : limits : cpu : 1000m memory : 2Gi requests : cpu : 1000m memory : 2Gi More information about the concept of resources can be found in the kuberentes documentation . Update Inventory and Profile \u00b6 Inventory and profiles in values.yaml is quite expensive from the Splunk Connect for SNMP perspective. It requires several checks before applying changes. SC4SNMP was designed to prevent changes in inventory and profiles task more often than every 5 min. When changing inventory or profile need to be applied in values.yaml following steps need to be done: Apply changes in values.yaml Check is inventory pod is still running by an execute command shell microk8s kubectl -n sc4snmp get pods | grep inventory If the command does not return any pods, follow the next step. In another case, wait and execute the command again until the moment when inventory job finishes. Run upgrade command describe in Installation Guide NOTE: If you decide to change existing profile scope without changing inventory data, the change will be reflected after next walk process for the host. Walk happens every walk_interval or on any change in inventory.","title":"Deployment"},{"location":"configuration/deployment-configuration/#deployment-configuration","text":"values.yaml are the main point of SC4SNMP management. The most important variables are already there from the very beginning after executing: microk8s helm3 inspect values splunk - connect - for - snmp / splunk - connect - for - snmp > values . yaml The whole file is divided into the following components: scheduler - more detail scheduler configuration worker - more detail worker configuration poller - more detail poller configuration sim - more detail sim configuration traps - more detail trap configuration mongodb - more detail mongo configuration rabbitmq - more detail rabbitmq configuration","title":"Deployment Configuration"},{"location":"configuration/deployment-configuration/#shared-values","text":"All of the components have the resources field for adjusting memory resources: resources : limits : cpu : 1000m memory : 2Gi requests : cpu : 1000m memory : 2Gi More information about the concept of resources can be found in the kuberentes documentation .","title":"Shared values"},{"location":"configuration/deployment-configuration/#update-inventory-and-profile","text":"Inventory and profiles in values.yaml is quite expensive from the Splunk Connect for SNMP perspective. It requires several checks before applying changes. SC4SNMP was designed to prevent changes in inventory and profiles task more often than every 5 min. When changing inventory or profile need to be applied in values.yaml following steps need to be done: Apply changes in values.yaml Check is inventory pod is still running by an execute command shell microk8s kubectl -n sc4snmp get pods | grep inventory If the command does not return any pods, follow the next step. In another case, wait and execute the command again until the moment when inventory job finishes. Run upgrade command describe in Installation Guide NOTE: If you decide to change existing profile scope without changing inventory data, the change will be reflected after next walk process for the host. Walk happens every walk_interval or on any change in inventory.","title":"Update Inventory and Profile"},{"location":"configuration/mongo-configuration/","text":"Mongo DB Configuration \u00b6 Mongo DB is used as the database for keeping schedules. Mongo DB configuration file \u00b6 Mongo DB configuration is kept in values.yaml file in section mongodb . values.yaml is being used during the installation process for configuring kubernetes values. Example: mongodb : #Architecture, Architecture for Mongo deployments is immutable to move from standalone to replicaset will require a uninstall. # \"replicaset\" for HA or multi node deployments # \"standalone\" for single node non HA #architecture: \"standalone\" pdb : create : true #The following requests and limits are appropriate starting points #For productions deployments resources : limits : cpu : 2 memory : 2Gi requests : cpu : 750m memory : 512Mi persistence : storageClass : \"microk8s-hostpath\" volumePermissions : enabled : true The recommendation is to do not change this setting. In case of need to change it please follow documentation: MongoDB on Kubernetes","title":"Mongo DB"},{"location":"configuration/mongo-configuration/#mongo-db-configuration","text":"Mongo DB is used as the database for keeping schedules.","title":"Mongo DB Configuration"},{"location":"configuration/mongo-configuration/#mongo-db-configuration-file","text":"Mongo DB configuration is kept in values.yaml file in section mongodb . values.yaml is being used during the installation process for configuring kubernetes values. Example: mongodb : #Architecture, Architecture for Mongo deployments is immutable to move from standalone to replicaset will require a uninstall. # \"replicaset\" for HA or multi node deployments # \"standalone\" for single node non HA #architecture: \"standalone\" pdb : create : true #The following requests and limits are appropriate starting points #For productions deployments resources : limits : cpu : 2 memory : 2Gi requests : cpu : 750m memory : 512Mi persistence : storageClass : \"microk8s-hostpath\" volumePermissions : enabled : true The recommendation is to do not change this setting. In case of need to change it please follow documentation: MongoDB on Kubernetes","title":"Mongo DB configuration file"},{"location":"configuration/poller-configuration/","text":"Poller Configuration \u00b6 The instruction contains configuration documentation for Poller. Poller is a service which is responsible for querying SNMP devices using SNMP GET, SNMP WALK functionality. Poller executes two main types of tasks: - Walk task execute SNMP walk. SNMP walk is an SNMP application that uses SNMP GETNEXT requests to collect SNMP data from network and infrastructure SNMP-enabled devices, such as switches and routers. It is a time-consuming task, which may overload the SNMP device when executing too often. It is used by SC4SNMP to collect and push all OIDs values which provided ACL has access to. - Get task - It is a lightweight task whose goal is to query a subset of OIDs defined by the customer. The task is dedicated to enabling monitoring of the most important OIDs with high frequency like memory or CPU utilization. Poller configuration file \u00b6 Poller configuration is kept in values.yaml file in section poller. values.yaml is being used during the installation process for configuring Kubernetes values. Poller example configuration: poller : logLevel : \"WARN\" inventory : | address,port,version,community,secret,securityEngine,walk_interval,profiles,SmartProfiles,delete 10.202.4.202,,2c,public,,,2000,,, NOTE: header\u2019s line ( address,port,version,community ) is necessary for the correct execution of SC4SNMP. Do not remove it. Define log level \u00b6 Log level for trap can be set by changing the value for key logLevel . Allowed values are: DEBUG , INFO , WARNING , ERROR . The default value is WARNING Configure inventory \u00b6 To update inventory follow instruction: Update Inventory and Profile inventory section in poller enable to configure inventory for polling data: address [REQUIRED] - IP address which SC4SNMP should connect to collect data from. port [OPTIONAL] - SNMP listening port. Default value 161 . version [REQUIRED] - SNMP version, allowed values: 1 , 2c or 3 community [OPTIONAL] - SNMP community string, filed is required when version is 1 or 2c secret [OPTIONAL] - usernameSecrets define which secrets in \u201cSecret\u201d objects in k8s should be use, as a value it need to put name of \u201cSecret\u201d objects. Field is required when version is 3 . More information how to define \u201cSecrets\u201d object for SNMPv3 can be found in SNMPv3 Configuration securityEngine [OPTIONAL] - Security engine required by SNMPv3. Field is required when version is 3 . walk_interval [OPTIONAL] - Define interval in second for SNMP walk, default value 42000 profiles [OPTIONAL] - list of SNMP profiles which need to be used for device. More than one profile can be added by semicolon separation eg. profiale1;profile2 . More about profile in Profile Configuration SmartProfiles [OPTIONAL] - enabled SmartProfile, default value true. Allowed value: true , false . Default value is true delete [OPTIONAL] - flags which define if inventory should be deleted from scheduled tasks for walk and gets. Allowed value: true , false . Default value is false . Example: poller : inventory : | address,port,version,community,secret,securityEngine,walk_interval,profiles,SmartProfiles,delete 10.202.4.202,,2c,public,,,2000,,,","title":"Poller"},{"location":"configuration/poller-configuration/#poller-configuration","text":"The instruction contains configuration documentation for Poller. Poller is a service which is responsible for querying SNMP devices using SNMP GET, SNMP WALK functionality. Poller executes two main types of tasks: - Walk task execute SNMP walk. SNMP walk is an SNMP application that uses SNMP GETNEXT requests to collect SNMP data from network and infrastructure SNMP-enabled devices, such as switches and routers. It is a time-consuming task, which may overload the SNMP device when executing too often. It is used by SC4SNMP to collect and push all OIDs values which provided ACL has access to. - Get task - It is a lightweight task whose goal is to query a subset of OIDs defined by the customer. The task is dedicated to enabling monitoring of the most important OIDs with high frequency like memory or CPU utilization.","title":"Poller Configuration"},{"location":"configuration/poller-configuration/#poller-configuration-file","text":"Poller configuration is kept in values.yaml file in section poller. values.yaml is being used during the installation process for configuring Kubernetes values. Poller example configuration: poller : logLevel : \"WARN\" inventory : | address,port,version,community,secret,securityEngine,walk_interval,profiles,SmartProfiles,delete 10.202.4.202,,2c,public,,,2000,,, NOTE: header\u2019s line ( address,port,version,community ) is necessary for the correct execution of SC4SNMP. Do not remove it.","title":"Poller configuration file"},{"location":"configuration/poller-configuration/#define-log-level","text":"Log level for trap can be set by changing the value for key logLevel . Allowed values are: DEBUG , INFO , WARNING , ERROR . The default value is WARNING","title":"Define log level"},{"location":"configuration/poller-configuration/#configure-inventory","text":"To update inventory follow instruction: Update Inventory and Profile inventory section in poller enable to configure inventory for polling data: address [REQUIRED] - IP address which SC4SNMP should connect to collect data from. port [OPTIONAL] - SNMP listening port. Default value 161 . version [REQUIRED] - SNMP version, allowed values: 1 , 2c or 3 community [OPTIONAL] - SNMP community string, filed is required when version is 1 or 2c secret [OPTIONAL] - usernameSecrets define which secrets in \u201cSecret\u201d objects in k8s should be use, as a value it need to put name of \u201cSecret\u201d objects. Field is required when version is 3 . More information how to define \u201cSecrets\u201d object for SNMPv3 can be found in SNMPv3 Configuration securityEngine [OPTIONAL] - Security engine required by SNMPv3. Field is required when version is 3 . walk_interval [OPTIONAL] - Define interval in second for SNMP walk, default value 42000 profiles [OPTIONAL] - list of SNMP profiles which need to be used for device. More than one profile can be added by semicolon separation eg. profiale1;profile2 . More about profile in Profile Configuration SmartProfiles [OPTIONAL] - enabled SmartProfile, default value true. Allowed value: true , false . Default value is true delete [OPTIONAL] - flags which define if inventory should be deleted from scheduled tasks for walk and gets. Allowed value: true , false . Default value is false . Example: poller : inventory : | address,port,version,community,secret,securityEngine,walk_interval,profiles,SmartProfiles,delete 10.202.4.202,,2c,public,,,2000,,,","title":"Configure inventory"},{"location":"configuration/rabbitmq-configuration/","text":"RabbitMQ configuration \u00b6 RabbitMQ is a service with is used as a queue service for SC4SNMP. It is queuing tasks like SNMP Walk and GETs. RabbitMQ configuration file \u00b6 RabbitMQ configuration is kept in values.yaml file in section rabbitmq . values.yaml is being used during the installation process for configuring Kubernetes values. Example: rabbitmq : pdb : create : true #For HA configuration at least three replicas should be used replicaCount : 1 persistence : enabled : true storageClass : \"microk8s-hostpath\" volumePermissions : enabled : true #The following requests and limits are appropriate starting points #For productions deployments resources : limits : cpu : 2 memory : 2Gi requests : cpu : 750m memory : 512Mi The recommendation is to do not to change this setting. In case of need to change it please follow documentation: RabbitMQ on Kubernetes","title":"RabbitMQ"},{"location":"configuration/rabbitmq-configuration/#rabbitmq-configuration","text":"RabbitMQ is a service with is used as a queue service for SC4SNMP. It is queuing tasks like SNMP Walk and GETs.","title":"RabbitMQ configuration"},{"location":"configuration/rabbitmq-configuration/#rabbitmq-configuration-file","text":"RabbitMQ configuration is kept in values.yaml file in section rabbitmq . values.yaml is being used during the installation process for configuring Kubernetes values. Example: rabbitmq : pdb : create : true #For HA configuration at least three replicas should be used replicaCount : 1 persistence : enabled : true storageClass : \"microk8s-hostpath\" volumePermissions : enabled : true #The following requests and limits are appropriate starting points #For productions deployments resources : limits : cpu : 2 memory : 2Gi requests : cpu : 750m memory : 512Mi The recommendation is to do not to change this setting. In case of need to change it please follow documentation: RabbitMQ on Kubernetes","title":"RabbitMQ configuration file"},{"location":"configuration/scheduler-configuration/","text":"Scheduler configuration \u00b6 The scheduler is a service with is responsible for managing schedules for SNMP walks and GETs. Schedules definition are stored in Mongo DB. Scheduler configuration file \u00b6 Scheduler configuration is kept in values.yaml file in section scheduler . values.yaml is being used during the installation process for configuring Kubernetes values. Example: scheduler : logLevel : \"WARN\" profiles : | test_profile: frequency: 5 condition: type: \"field\" field: \"SNMPv2-MIB.sysDescr\" patterns: - \"^.*\" varBinds: # Syntax: [ \"MIB-Component\", \"MIB object name\"[Optional], \"MIB index number\"[Optional]] - [\"SNMPv2-MIB\", \"sysDescr\",0] Define log level \u00b6 Log level for trap can be set by changing the value for key logLevel . Allowed values are: DEBUG , INFO , WARNING , ERROR . The default value is WARNING Define resource requests and limits \u00b6 scheduler : #The following resource specification is appropriate for most deployments to scale the #Larger inventories may require more memory but should not require additional cpu resources : limits : cpu : 1 memory : 1Gi requests : cpu : 200m memory : 128Mi Configure profile \u00b6 To update profile follow instruction: Update Inventory and Profile . Profiles used in inventory can be created in values.yaml , which can be modified in scheduler config in values.yaml , example: scheduler : profiles : | #Name of profile basev1: # Define frequency for profile frequency: 10 #Define condition condition: # Define type of condition. Allowed value field and base type: field field: \"SNMPv2-MIB.sysDescr\" # Define paterns patterns: - '.*STRING_TO_BE_MATCHED.*' #Define varbinds to query varBinds: # Syntax: [ \"MIB-Component\", \"MIB object name\"[Optional], \"MIB index number\"[Optional]] - ['SNMPv2-MIB'] - ['SNMPv2-MIB', 'sysName'] - ['SNMPv2-MIB', 'sysUpTime',0] varBinds configuration \u00b6 varBinds short for \u201cvariable binding\u201d in SNMP. The combination of an Object Identifier (OID) and a value. varBinds are used for defining in profiles what OIDs should be getting from SNMP Agents. varBinds is a required subsection of each profile. Syntax configuration of varBinds looks following: [ \u201cMIB-Component\u201d, \u201cMIB object\u201d[Optional], \u201cMIB index number\u201d[Optional]] MIB-Component - The SNMP MIB, itself, consists of distinct component MIBs, each of which refers to a specific defined collection of management information that is part of the overall SNMP MIB eg. SNMPv2-MIB . If only MIB-Component is set then all whole subtree is getting. MIB object - The SNMP MIB stores only simple data types: scalars and two-dimensional arrays of scalars, called tables. Keywords SYNTAX, ACCESS, and DESCRIPTION as well as other keywords such as STATUS and INDEX is used to define the SNMP MIB managed objects. MIB index number - Define index number for given MIB Object eg. 0 . Example: varBinds : # Syntax: [ \"MIB-Component\", \"MIB object name\"[Optional], \"MIB index number\"[Optional]] - [ 'SNMPv2-MIB' ] - [ 'SNMPv2-MIB' , 'sysName' ] - [ 'SNMPv2-MIB' , 'sysUpTime' , 0 ] Static Profile configuration \u00b6 Static Profile are used when they are defined on a list of profiles in inventory configuration in poller service Inventory configuration . Static Profiles are executed even if the SmartProfile flag in inventory is set to false. To configure Static Profile following value needs to be set in profiles section: ProfileName - define as subsection key in profiles . frequency - define interval between executing SNMP gets in second. varBinds - define var binds to query. Example: scheduler : profiles : | static_profile_example: frequency: 20 varBinds: - ['SNMPv2-MIB'] - ['SNMPv2-MIB', 'sysName'] - ['SNMPv2-MIB', 'sysUpTime',0] SmartProfile configuration \u00b6 SmartProfile is executed when the SmartProfile flag in inventory is set to true and the condition defined in profile matching. More information about configuring inventory can be found in Inventory configuration To configure Static Profile following value needs to be set in profiles section: ProfileName - define as subsection key in profiles . frequency - define interval between executing SNMP gets in second. condition - section define conditions to much profile type - key of condition section which defines type of condition. Allowed value base and field . base type of condition will be executed when SmartProfile in inventory is set to true. walk such profile will be executed instead of full walk field type of condition will be executed if match pattern for defined field . Supported fields: \u201cSNMPv2-MIB.sysDescr\u201d \u201cSNMPv2-MIB.sysObjectID\u201d field Define field name for condition type field. pattern Define list of regular expression pattern for MIB object field defined in field section. varBinds - define var binds to query. Example of base type of condition scheduler : profiles : | SmartProfile_base_example: frequency: 10 condition: type: \"base\" varBinds: - ['SNMPv2-MIB'] - ['SNMPv2-MIB', 'sysName'] Example of field type of condition scheduler : profiles : | SmartProfile_field_example: frequency: 10 condition: type: \"field\" field: \"SNMPv2-MIB.sysDescr\" patterns: - '.*STRING_TO_BE_MATCHED.*' varBinds: - ['SNMPv2-MIB'] - ['SNMPv2-MIB', 'sysName'] NOTE: Be aware that profile changes may not be reflected immediately. It can take up to 5 minutes for changes to propagate. There is also 5 minute TTL for an inventory pod. Basically, SC4SNMP allows one inventory upgrade and then block updates for the next 5 minutes Custom translations \u00b6 If the user wants to use custom names/translations of MIB names, it can be configured under customTranslations section under scheduler config. Translations are grouped by MIB family. In the example below IF-MIB.ifInDiscards will be translated to IF-MIB.myCustomName1 scheduler : customTranslations : IF-MIB : ifInDiscards : myCustomName1 ifOutErrors : myCustomName2 SNMPv2-MIB : sysDescr : myCustomName3","title":"Scheduler"},{"location":"configuration/scheduler-configuration/#scheduler-configuration","text":"The scheduler is a service with is responsible for managing schedules for SNMP walks and GETs. Schedules definition are stored in Mongo DB.","title":"Scheduler configuration"},{"location":"configuration/scheduler-configuration/#scheduler-configuration-file","text":"Scheduler configuration is kept in values.yaml file in section scheduler . values.yaml is being used during the installation process for configuring Kubernetes values. Example: scheduler : logLevel : \"WARN\" profiles : | test_profile: frequency: 5 condition: type: \"field\" field: \"SNMPv2-MIB.sysDescr\" patterns: - \"^.*\" varBinds: # Syntax: [ \"MIB-Component\", \"MIB object name\"[Optional], \"MIB index number\"[Optional]] - [\"SNMPv2-MIB\", \"sysDescr\",0]","title":"Scheduler configuration file"},{"location":"configuration/scheduler-configuration/#define-log-level","text":"Log level for trap can be set by changing the value for key logLevel . Allowed values are: DEBUG , INFO , WARNING , ERROR . The default value is WARNING","title":"Define log level"},{"location":"configuration/scheduler-configuration/#define-resource-requests-and-limits","text":"scheduler : #The following resource specification is appropriate for most deployments to scale the #Larger inventories may require more memory but should not require additional cpu resources : limits : cpu : 1 memory : 1Gi requests : cpu : 200m memory : 128Mi","title":"Define resource requests and limits"},{"location":"configuration/scheduler-configuration/#configure-profile","text":"To update profile follow instruction: Update Inventory and Profile . Profiles used in inventory can be created in values.yaml , which can be modified in scheduler config in values.yaml , example: scheduler : profiles : | #Name of profile basev1: # Define frequency for profile frequency: 10 #Define condition condition: # Define type of condition. Allowed value field and base type: field field: \"SNMPv2-MIB.sysDescr\" # Define paterns patterns: - '.*STRING_TO_BE_MATCHED.*' #Define varbinds to query varBinds: # Syntax: [ \"MIB-Component\", \"MIB object name\"[Optional], \"MIB index number\"[Optional]] - ['SNMPv2-MIB'] - ['SNMPv2-MIB', 'sysName'] - ['SNMPv2-MIB', 'sysUpTime',0]","title":"Configure profile"},{"location":"configuration/scheduler-configuration/#varbinds-configuration","text":"varBinds short for \u201cvariable binding\u201d in SNMP. The combination of an Object Identifier (OID) and a value. varBinds are used for defining in profiles what OIDs should be getting from SNMP Agents. varBinds is a required subsection of each profile. Syntax configuration of varBinds looks following: [ \u201cMIB-Component\u201d, \u201cMIB object\u201d[Optional], \u201cMIB index number\u201d[Optional]] MIB-Component - The SNMP MIB, itself, consists of distinct component MIBs, each of which refers to a specific defined collection of management information that is part of the overall SNMP MIB eg. SNMPv2-MIB . If only MIB-Component is set then all whole subtree is getting. MIB object - The SNMP MIB stores only simple data types: scalars and two-dimensional arrays of scalars, called tables. Keywords SYNTAX, ACCESS, and DESCRIPTION as well as other keywords such as STATUS and INDEX is used to define the SNMP MIB managed objects. MIB index number - Define index number for given MIB Object eg. 0 . Example: varBinds : # Syntax: [ \"MIB-Component\", \"MIB object name\"[Optional], \"MIB index number\"[Optional]] - [ 'SNMPv2-MIB' ] - [ 'SNMPv2-MIB' , 'sysName' ] - [ 'SNMPv2-MIB' , 'sysUpTime' , 0 ]","title":"varBinds configuration"},{"location":"configuration/scheduler-configuration/#static-profile-configuration","text":"Static Profile are used when they are defined on a list of profiles in inventory configuration in poller service Inventory configuration . Static Profiles are executed even if the SmartProfile flag in inventory is set to false. To configure Static Profile following value needs to be set in profiles section: ProfileName - define as subsection key in profiles . frequency - define interval between executing SNMP gets in second. varBinds - define var binds to query. Example: scheduler : profiles : | static_profile_example: frequency: 20 varBinds: - ['SNMPv2-MIB'] - ['SNMPv2-MIB', 'sysName'] - ['SNMPv2-MIB', 'sysUpTime',0]","title":"Static Profile configuration"},{"location":"configuration/scheduler-configuration/#smartprofile-configuration","text":"SmartProfile is executed when the SmartProfile flag in inventory is set to true and the condition defined in profile matching. More information about configuring inventory can be found in Inventory configuration To configure Static Profile following value needs to be set in profiles section: ProfileName - define as subsection key in profiles . frequency - define interval between executing SNMP gets in second. condition - section define conditions to much profile type - key of condition section which defines type of condition. Allowed value base and field . base type of condition will be executed when SmartProfile in inventory is set to true. walk such profile will be executed instead of full walk field type of condition will be executed if match pattern for defined field . Supported fields: \u201cSNMPv2-MIB.sysDescr\u201d \u201cSNMPv2-MIB.sysObjectID\u201d field Define field name for condition type field. pattern Define list of regular expression pattern for MIB object field defined in field section. varBinds - define var binds to query. Example of base type of condition scheduler : profiles : | SmartProfile_base_example: frequency: 10 condition: type: \"base\" varBinds: - ['SNMPv2-MIB'] - ['SNMPv2-MIB', 'sysName'] Example of field type of condition scheduler : profiles : | SmartProfile_field_example: frequency: 10 condition: type: \"field\" field: \"SNMPv2-MIB.sysDescr\" patterns: - '.*STRING_TO_BE_MATCHED.*' varBinds: - ['SNMPv2-MIB'] - ['SNMPv2-MIB', 'sysName'] NOTE: Be aware that profile changes may not be reflected immediately. It can take up to 5 minutes for changes to propagate. There is also 5 minute TTL for an inventory pod. Basically, SC4SNMP allows one inventory upgrade and then block updates for the next 5 minutes","title":"SmartProfile configuration"},{"location":"configuration/scheduler-configuration/#custom-translations","text":"If the user wants to use custom names/translations of MIB names, it can be configured under customTranslations section under scheduler config. Translations are grouped by MIB family. In the example below IF-MIB.ifInDiscards will be translated to IF-MIB.myCustomName1 scheduler : customTranslations : IF-MIB : ifInDiscards : myCustomName1 ifOutErrors : myCustomName2 SNMPv2-MIB : sysDescr : myCustomName3","title":"Custom translations"},{"location":"configuration/sim-configuration/","text":"Otel configuration \u00b6 Splunk OpenTelemetry Collector is a component that provides an option to send metrics to SignalFx. In order to use it, you must set enabled flag in values.yaml to true : sim : # sim must be enabled if you want to use SignalFx enabled : true Also, you need to specify SignalFx token and realm, so at the end sim element in values.yaml looks like this: sim : enabled : true signalfxToken : BCwaJ_Ands4Xh7Nrg signalfxRealm : us0 After executing microk8s helm3 upgrade --install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace=sc4snmp --create-namespace , the sim pod should be up and running: splunker@ip-10-202-13-233:~$ microk8s kubectl get pods -n sc4snmp NAME READY STATUS RESTARTS AGE snmp-splunk-connect-for-snmp-worker-7496b66947-6hjhl 1/1 Running 0 32s snmp-splunk-connect-for-snmp-worker-7496b66947-flcg7 1/1 Running 0 32s snmp-splunk-connect-for-snmp-scheduler-846f9b4f69-4rxd8 1/1 Running 0 32s snmp-mibserver-cdfccf586-cwz7h 1/1 Running 0 32s snmp-splunk-connect-for-snmp-inventory--1-dxz5d 1/1 Running 0 32s snmp-splunk-connect-for-snmp-traps-6bbf57497b-v8d7l 1/1 Running 0 32s snmp-splunk-connect-for-snmp-traps-6bbf57497b-nvxrz 1/1 Running 0 31s snmp-splunk-connect-for-snmp-sim-59b89747f-kn6tf 1/1 Running 0 32s snmp-rabbitmq-0 0/1 Running 0 31s snmp-mongodb-9957b9f4d-f94hv 2/2 Running 0 32s","title":"Splunk Infrastructure Monitoring"},{"location":"configuration/sim-configuration/#otel-configuration","text":"Splunk OpenTelemetry Collector is a component that provides an option to send metrics to SignalFx. In order to use it, you must set enabled flag in values.yaml to true : sim : # sim must be enabled if you want to use SignalFx enabled : true Also, you need to specify SignalFx token and realm, so at the end sim element in values.yaml looks like this: sim : enabled : true signalfxToken : BCwaJ_Ands4Xh7Nrg signalfxRealm : us0 After executing microk8s helm3 upgrade --install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace=sc4snmp --create-namespace , the sim pod should be up and running: splunker@ip-10-202-13-233:~$ microk8s kubectl get pods -n sc4snmp NAME READY STATUS RESTARTS AGE snmp-splunk-connect-for-snmp-worker-7496b66947-6hjhl 1/1 Running 0 32s snmp-splunk-connect-for-snmp-worker-7496b66947-flcg7 1/1 Running 0 32s snmp-splunk-connect-for-snmp-scheduler-846f9b4f69-4rxd8 1/1 Running 0 32s snmp-mibserver-cdfccf586-cwz7h 1/1 Running 0 32s snmp-splunk-connect-for-snmp-inventory--1-dxz5d 1/1 Running 0 32s snmp-splunk-connect-for-snmp-traps-6bbf57497b-v8d7l 1/1 Running 0 32s snmp-splunk-connect-for-snmp-traps-6bbf57497b-nvxrz 1/1 Running 0 31s snmp-splunk-connect-for-snmp-sim-59b89747f-kn6tf 1/1 Running 0 32s snmp-rabbitmq-0 0/1 Running 0 31s snmp-mongodb-9957b9f4d-f94hv 2/2 Running 0 32s","title":"Otel configuration"},{"location":"configuration/snmpv3-configuration/","text":"Create SNMP v3 users \u00b6 Configuration of SNMP v3, when supported by the monitored devices, is the most secure choice available for authentication and data privacy. Each set of credentials will be stored as \u201cSecret\u201d objects in k8s and will be referenced in the values.yaml. This allows the secret to being created once including automation by third-party password managers then consumed without storing sensitive data in plain text. # <secretname>=Arbitrary name of the secret often the same as the username or prefixed with \"sc4snmp-\" # <namespace>=Namespace used to install sc4snmp # <username>=the SNMPv3 Username # <key>=key note must be at least 8 char long subject to target limitations # <authProtocol>=One of SHA (SHA1) or MD5 # <privProtocol>=One of AES or DES # Note MD5 and DES are considered insecure but must be supported for standards compliance kubectl create -n <namespace> secret generic <secretname> \\ --from-literal = userName = <username> \\ --from-literal = authKey = <key> \\ --from-literal = privKey = <key> \\ --from-literal = authProtocol = <authProtocol> \\ --from-literal = privProtocol = <privProtocol> Configured credential can be use in poller and trap services. In services configuration, secretname need to be provided.","title":"SNMPv3 configuration"},{"location":"configuration/snmpv3-configuration/#create-snmp-v3-users","text":"Configuration of SNMP v3, when supported by the monitored devices, is the most secure choice available for authentication and data privacy. Each set of credentials will be stored as \u201cSecret\u201d objects in k8s and will be referenced in the values.yaml. This allows the secret to being created once including automation by third-party password managers then consumed without storing sensitive data in plain text. # <secretname>=Arbitrary name of the secret often the same as the username or prefixed with \"sc4snmp-\" # <namespace>=Namespace used to install sc4snmp # <username>=the SNMPv3 Username # <key>=key note must be at least 8 char long subject to target limitations # <authProtocol>=One of SHA (SHA1) or MD5 # <privProtocol>=One of AES or DES # Note MD5 and DES are considered insecure but must be supported for standards compliance kubectl create -n <namespace> secret generic <secretname> \\ --from-literal = userName = <username> \\ --from-literal = authKey = <key> \\ --from-literal = privKey = <key> \\ --from-literal = authProtocol = <authProtocol> \\ --from-literal = privProtocol = <privProtocol> Configured credential can be use in poller and trap services. In services configuration, secretname need to be provided.","title":"Create SNMP v3 users"},{"location":"configuration/trap-configuration/","text":"Trap Configuration \u00b6 A trap service is a simple server that can handle SNMP traps sent by SNMP devices like routers or switches. Trap configuration file \u00b6 Trap configuration is kept in values.yaml file in section traps. values.yaml is being used during the installation process for configuring Kubernetes values. Trap example configuration: traps : communities : 1 : - public 2c : - public - homelab usernameSecrets : - secretv3 - sc4snmp-homesecure-sha-des # Overrides the image tag whose default is the chart appVersion. logLevel : \"WARN\" # replicas: Number of replicas for trap container should be 2x number of nodes replicas : 2 #loadBalancerIP: The IP address in the metallb pool loadBalancerIP : 10.202.4.202 resources : limits : cpu : 500m memory : 512Mi requests : cpu : 200m memory : 256Mi Define communities \u00b6 communities define a version of SNMP protocol and SNMP community string which should be used. communities key is split by protocol version, supported values are 1 and 2c . Under version section, SNMP community string can be defined. Example: traps : communities : 1 : - public 2c : - public - homelab Configure user secrets for SNMPv3 \u00b6 usernameSecrets key in the traps section define SNMPv3 secrets for trap messages sent by SNMP device. usernameSecrets define which secrets in \u201cSecret\u201d objects in k8s should be used, as a value it needs to put the name of \u201cSecret\u201d objects. More information on how to define the \u201cSecret\u201d object for SNMPv3 can be found in SNMPv3 Configuration Example: traps : usernameSecrets : - sc4snmp-homesecure-sha-aes - sc4snmp-homesecure-sha-des Define security engine ID for SNMPv3 \u00b6 Security engine ID variable is necessary when sending SNMPv3 traps. By default, it is set to 8000000903000A397056B8AC . It has to match the -e string in snmptrap. Example: traps : securityEngineId : \"8000000903000A397056B8AC\" An example of SNMPv3 trap is: snmptrap -v3 -l authPriv -u snmp-poller -a SHA -A PASSWORD1 -x AES -X PASSWORD1 10.202.13.233 '' 1.3.6.1.2.1.2.2.1.1.1 Define load balancer IP \u00b6 loadBalancerIP is the IP address in the metallb pool. Example: traps : loadBalancerIP : 10.202.4.202 Define number of traps server replica \u00b6 replicas Defines the number of replicas for trap container should be 2x number of nodes. The default value is 2 . Example: traps : #For production deployments the value should be 2x the number of nodes # Minimum 2 for a single node # Minimum 6 for multi-node HA replicaCount : 2 Define log level \u00b6 Log level for trap can be set by changing the value for key logLevel . Allowed values are: DEBUG , INFO , WARNING , ERROR . The default value is WARNING","title":"Trap"},{"location":"configuration/trap-configuration/#trap-configuration","text":"A trap service is a simple server that can handle SNMP traps sent by SNMP devices like routers or switches.","title":"Trap Configuration"},{"location":"configuration/trap-configuration/#trap-configuration-file","text":"Trap configuration is kept in values.yaml file in section traps. values.yaml is being used during the installation process for configuring Kubernetes values. Trap example configuration: traps : communities : 1 : - public 2c : - public - homelab usernameSecrets : - secretv3 - sc4snmp-homesecure-sha-des # Overrides the image tag whose default is the chart appVersion. logLevel : \"WARN\" # replicas: Number of replicas for trap container should be 2x number of nodes replicas : 2 #loadBalancerIP: The IP address in the metallb pool loadBalancerIP : 10.202.4.202 resources : limits : cpu : 500m memory : 512Mi requests : cpu : 200m memory : 256Mi","title":"Trap configuration file"},{"location":"configuration/trap-configuration/#define-communities","text":"communities define a version of SNMP protocol and SNMP community string which should be used. communities key is split by protocol version, supported values are 1 and 2c . Under version section, SNMP community string can be defined. Example: traps : communities : 1 : - public 2c : - public - homelab","title":"Define communities"},{"location":"configuration/trap-configuration/#configure-user-secrets-for-snmpv3","text":"usernameSecrets key in the traps section define SNMPv3 secrets for trap messages sent by SNMP device. usernameSecrets define which secrets in \u201cSecret\u201d objects in k8s should be used, as a value it needs to put the name of \u201cSecret\u201d objects. More information on how to define the \u201cSecret\u201d object for SNMPv3 can be found in SNMPv3 Configuration Example: traps : usernameSecrets : - sc4snmp-homesecure-sha-aes - sc4snmp-homesecure-sha-des","title":"Configure user secrets for SNMPv3"},{"location":"configuration/trap-configuration/#define-security-engine-id-for-snmpv3","text":"Security engine ID variable is necessary when sending SNMPv3 traps. By default, it is set to 8000000903000A397056B8AC . It has to match the -e string in snmptrap. Example: traps : securityEngineId : \"8000000903000A397056B8AC\" An example of SNMPv3 trap is: snmptrap -v3 -l authPriv -u snmp-poller -a SHA -A PASSWORD1 -x AES -X PASSWORD1 10.202.13.233 '' 1.3.6.1.2.1.2.2.1.1.1","title":"Define security engine ID for SNMPv3"},{"location":"configuration/trap-configuration/#define-load-balancer-ip","text":"loadBalancerIP is the IP address in the metallb pool. Example: traps : loadBalancerIP : 10.202.4.202","title":"Define load balancer IP"},{"location":"configuration/trap-configuration/#define-number-of-traps-server-replica","text":"replicas Defines the number of replicas for trap container should be 2x number of nodes. The default value is 2 . Example: traps : #For production deployments the value should be 2x the number of nodes # Minimum 2 for a single node # Minimum 6 for multi-node HA replicaCount : 2","title":"Define number of traps server replica"},{"location":"configuration/trap-configuration/#define-log-level","text":"Log level for trap can be set by changing the value for key logLevel . Allowed values are: DEBUG , INFO , WARNING , ERROR . The default value is WARNING","title":"Define log level"},{"location":"configuration/worker-configuration/","text":"Worker Configuration \u00b6 The worker is a service with is responsible for tasks execution like SNMP Walk, GET, or processing trap messages. Worker configuration file \u00b6 Worker configuration is kept in values.yaml file in section worker . values.yaml is being used during the installation process for configuring Kubernetes values. worker : # replicas: The number of replicas for worker containers should be two or more replicaCount : 2 #Log level one of INFO, WARNING, CRITICAL, DEBUG, ERROR logLevel : \"WARNING\" #The following resource specification is appropriate for most deployments to scale the #Environment increase the number of workers rather than the resources per container resources : limits : cpu : 2 memory : 512Mi requests : cpu : 500m memory : 128Mi","title":"Worker"},{"location":"configuration/worker-configuration/#worker-configuration","text":"The worker is a service with is responsible for tasks execution like SNMP Walk, GET, or processing trap messages.","title":"Worker Configuration"},{"location":"configuration/worker-configuration/#worker-configuration-file","text":"Worker configuration is kept in values.yaml file in section worker . values.yaml is being used during the installation process for configuring Kubernetes values. worker : # replicas: The number of replicas for worker containers should be two or more replicaCount : 2 #Log level one of INFO, WARNING, CRITICAL, DEBUG, ERROR logLevel : \"WARNING\" #The following resource specification is appropriate for most deployments to scale the #Environment increase the number of workers rather than the resources per container resources : limits : cpu : 2 memory : 512Mi requests : cpu : 500m memory : 128Mi","title":"Worker configuration file"},{"location":"gettingstarted/sc4snmp-installation/","text":"SC4SNMP Helm installation \u00b6 The basic installation process and configuration used in this section are typical for single node non HA deployments and do not have resource requests and limits. See the configuration sections for mongo, Rabbitmq, scheduler, worker, and traps for guidance on production configuration. Add SC4SNMP repository \u00b6 microk8s helm3 repo add splunk - connect - for - snmp https : // splunk . github . io / splunk - connect - for - snmp microk8s helm3 repo update Now the package should be visible in helm3 search command result: microk8s helm3 search repo snmp Example output: NAME CHART VERSION APP VERSION DESCRIPTION splunk - connect - for - snmp / splunk - connect - for - snmp 1 . 0 . 0 1 . 0 . 0 A Helm chart for SNMP Connect for SNMP Download and modify values.yaml \u00b6 splunk : enabled : true protocol : https host : ###SPLUNK_HOST### token : ###SPLUNK_TOKEN### insecureSSL : \"false\" port : \"###SPLUNK_PORT###\" image : pullPolicy : \"Always\" traps : communities : 2c : - public - homelab #usernameSecrets: # - sc4snmp-hlab-sha-aes # - sc4snmp-hlab-sha-des #loadBalancerIP: The IP address in the metallb pool loadBalancerIP : ###X.X.X.X### worker : # replicas: Number of replicas for worker container should two or more #replicaCount: 2 # udpConnectionTimeout: timeout in seconds for SNMP operations #udpConnectionTimeout: 5 logLevel : \"INFO\" scheduler : logLevel : \"INFO\" # profiles: | # generic_switch: # frequency: 60 # varBinds: # - ['SNMPv2-MIB', 'sysDescr'] # - ['SNMPv2-MIB', 'sysName', 0] # - ['IF-MIB'] # - ['TCP-MIB'] # - ['UDP-MIB'] poller : # usernameSecrets: # - sc4snmp-hlab-sha-aes # - sc4snmp-hlab-sha-des # inventory: | # address,port,version,community,secret,securityEngine,walk_interval,profiles,SmartProfiles,delete # 10.0.0.1,,3,,sc4snmp-hlab-sha-aes,,600,,, # 10.0.0.199,,2c,public,,,600,,,True # 10.0.0.100,,3,,sc4snmp-hlab-sha-des,,600,,, sim : # sim must be enabled if you want to use signalFx enabled : false # signalfxToken: BCwaJ_Ands4Xh7Nrg # signalfxRealm: us0 mongodb : pdb : create : true persistence : storageClass : \"microk8s-hostpath\" volumePermissions : enabled : true rabbitmq : pdb : create : true replicaCount : 1 persistence : enabled : true storageClass : \"microk8s-hostpath\" volumePermissions : enabled : true values.yaml is being used during the installation process for configuring Kubernetes values. Configure Splunk Enterprise or Splunk Cloud Connection \u00b6 Splunk Enterprise or Splunk Cloud connection is enabled by default, to disable Splunk Enterprise or Splunk Cloud splunk.enabled property must be set to false . Additionally, connection parameters for Splunk Enterprise or Splunk Cloud needs to be set in splunk section: Placeholder Description Example ###SPLUNK_HOST### host address of splunk instance \u201ci-08c221389a3b9899a.ec2.splunkit.io\u201d ###SPLUNK_PORT### port number of splunk instance \u201c8088\u201d ###SPLUNK_TOKEN### Splunk HTTP Event Collector token 450a69af-16a9-4f87-9628-c26f04ad3785 ###X.X.X.X### SHARED IP address used for SNMP Traps 10.202.18.166 Other optional variables can be configured: variable description default splunk.protocol port of splunk instance https splunk.insecure_ssl is insecure ssl allowed \u201ctrue\u201d splunk.eventIndex name of the events index \u201cnetops\u201d splunk.metricsIndex name of the metrics index \u201cnetmetrics\u201d Configure Splunk Infrastructure Monitoring Connection \u00b6 Splunk Infrastructure Monitoring is disabled by default, to enable Splunk Infrastructure Monitoring sim.enabled property must be set to true . Additionally, connection parameters for Splunk Infrastructure Monitoring need to be set in sim section: variable description default signalfxToken SIM token which can be use for ingesting date vi API not set signalfxRealm Real of SIM not set For more details please check SIM Configuration Install SC4SNMP \u00b6 microk8s helm3 install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace From now on, when editing SC4SNMP configuration, the configuration change must be inserted in the corresponding section of values.yaml . For more details check configuration section. Use the following command to propagate configuration changes: microk8s helm3 upgrade --install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace Verify deployment \u00b6 In a few minutes, all pods should be up and running. It can be verified with: microk8s kubectl get pods -n sc4snmp Example output: NAME READY STATUS RESTARTS AGE snmp - splunk - connect - for - snmp - worker - 66685 fcb6d - f6rxb 1 / 1 Running 0 6 m4s snmp - splunk - connect - for - snmp - scheduler - 6586488 d85 - t6j5d 1 / 1 Running 0 6 m4s snmp - mongodb - arbiter - 0 1 / 1 Running 0 6 m4s snmp - mibserver - 6 f575ddb7d - mmkmn 1 / 1 Running 0 6 m4s snmp - mongodb - 0 2 / 2 Running 0 6 m4s snmp - mongodb - 1 2 / 2 Running 0 4 m58s snmp - rabbitmq - 0 1 / 1 Running 0 6 m4s snmp - splunk - connect - for - snmp - traps - 54 f79b945d - bmbg7 1 / 1 Running 0 6 m4s Test SNMP Traps \u00b6 Test the Trap by logging into Splunk and confirming the presence of events in snmp netops and metrics in netmetrics index Test the trap from a Linux system with SNMP installed. Replace the IP address 10.0.101.22 with the shared IP address above apt update apt-get install snmpd snmptrap -v2c -c public 10 .0.101.22 123 1 .3.6.1.2.1.1.4 1 .3.6.1.2.1.1.4 s test Search Splunk: You should see one event per trap command with the host value of the test machine IP address index = \"netops\" sourcetype = \"sc4snmp:traps\" Test SNMP Poller \u00b6 Test the Poller by logging into Splunk and confirming the presence of events in snmp netops and metrics in netmetrics index Test the trap from a Linux system install snmpd. apt update apt-get install snmpd To test SNMP poller, snmpd needs to be configured to listen on external IP. To enabled listening snmpd to external IP, in configuration file: /etc/snmp/snmpd.conf replace the IP address 10.0.101.22 with the server IP address where snmpd is configured agentaddress 10.0.101.22,127.0.0.1,[::1] . Restart snmpd by execute command: service snmpd stop service snmpd start Configure SC4SNMP Poller to test add IP address which need to be poll. Add configuration entry in value.yaml file by replace the IP address 10.0.101.22 with the server IP address where snmpd were configured. poller: usernameSecrets: - sc4snmp-homesecure-sha-aes - sc4snmp-homesecure-sha-des inventory: | address,version,community,walk_interval,profiles,SmartProfiles,delete 10 .0.101.22,public,60,,, Load value.yaml file in SC4SNMP microk8s helm3 upgrade --install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace Check-in Splunk Up to 1 min events appear in Splunk: index = \"netops\" sourcetype = \"sc4snmp:event\" Up to 1 min events appear in Splunk: | mpreview index = \"netmetrics\" | search sourcetype = \"sc4snmp:metric\"","title":"Install SC4SNMP"},{"location":"gettingstarted/sc4snmp-installation/#sc4snmp-helm-installation","text":"The basic installation process and configuration used in this section are typical for single node non HA deployments and do not have resource requests and limits. See the configuration sections for mongo, Rabbitmq, scheduler, worker, and traps for guidance on production configuration.","title":"SC4SNMP Helm installation"},{"location":"gettingstarted/sc4snmp-installation/#add-sc4snmp-repository","text":"microk8s helm3 repo add splunk - connect - for - snmp https : // splunk . github . io / splunk - connect - for - snmp microk8s helm3 repo update Now the package should be visible in helm3 search command result: microk8s helm3 search repo snmp Example output: NAME CHART VERSION APP VERSION DESCRIPTION splunk - connect - for - snmp / splunk - connect - for - snmp 1 . 0 . 0 1 . 0 . 0 A Helm chart for SNMP Connect for SNMP","title":"Add SC4SNMP repository"},{"location":"gettingstarted/sc4snmp-installation/#download-and-modify-valuesyaml","text":"splunk : enabled : true protocol : https host : ###SPLUNK_HOST### token : ###SPLUNK_TOKEN### insecureSSL : \"false\" port : \"###SPLUNK_PORT###\" image : pullPolicy : \"Always\" traps : communities : 2c : - public - homelab #usernameSecrets: # - sc4snmp-hlab-sha-aes # - sc4snmp-hlab-sha-des #loadBalancerIP: The IP address in the metallb pool loadBalancerIP : ###X.X.X.X### worker : # replicas: Number of replicas for worker container should two or more #replicaCount: 2 # udpConnectionTimeout: timeout in seconds for SNMP operations #udpConnectionTimeout: 5 logLevel : \"INFO\" scheduler : logLevel : \"INFO\" # profiles: | # generic_switch: # frequency: 60 # varBinds: # - ['SNMPv2-MIB', 'sysDescr'] # - ['SNMPv2-MIB', 'sysName', 0] # - ['IF-MIB'] # - ['TCP-MIB'] # - ['UDP-MIB'] poller : # usernameSecrets: # - sc4snmp-hlab-sha-aes # - sc4snmp-hlab-sha-des # inventory: | # address,port,version,community,secret,securityEngine,walk_interval,profiles,SmartProfiles,delete # 10.0.0.1,,3,,sc4snmp-hlab-sha-aes,,600,,, # 10.0.0.199,,2c,public,,,600,,,True # 10.0.0.100,,3,,sc4snmp-hlab-sha-des,,600,,, sim : # sim must be enabled if you want to use signalFx enabled : false # signalfxToken: BCwaJ_Ands4Xh7Nrg # signalfxRealm: us0 mongodb : pdb : create : true persistence : storageClass : \"microk8s-hostpath\" volumePermissions : enabled : true rabbitmq : pdb : create : true replicaCount : 1 persistence : enabled : true storageClass : \"microk8s-hostpath\" volumePermissions : enabled : true values.yaml is being used during the installation process for configuring Kubernetes values.","title":"Download and modify values.yaml"},{"location":"gettingstarted/sc4snmp-installation/#configure-splunk-enterprise-or-splunk-cloud-connection","text":"Splunk Enterprise or Splunk Cloud connection is enabled by default, to disable Splunk Enterprise or Splunk Cloud splunk.enabled property must be set to false . Additionally, connection parameters for Splunk Enterprise or Splunk Cloud needs to be set in splunk section: Placeholder Description Example ###SPLUNK_HOST### host address of splunk instance \u201ci-08c221389a3b9899a.ec2.splunkit.io\u201d ###SPLUNK_PORT### port number of splunk instance \u201c8088\u201d ###SPLUNK_TOKEN### Splunk HTTP Event Collector token 450a69af-16a9-4f87-9628-c26f04ad3785 ###X.X.X.X### SHARED IP address used for SNMP Traps 10.202.18.166 Other optional variables can be configured: variable description default splunk.protocol port of splunk instance https splunk.insecure_ssl is insecure ssl allowed \u201ctrue\u201d splunk.eventIndex name of the events index \u201cnetops\u201d splunk.metricsIndex name of the metrics index \u201cnetmetrics\u201d","title":"Configure Splunk Enterprise or Splunk Cloud Connection"},{"location":"gettingstarted/sc4snmp-installation/#configure-splunk-infrastructure-monitoring-connection","text":"Splunk Infrastructure Monitoring is disabled by default, to enable Splunk Infrastructure Monitoring sim.enabled property must be set to true . Additionally, connection parameters for Splunk Infrastructure Monitoring need to be set in sim section: variable description default signalfxToken SIM token which can be use for ingesting date vi API not set signalfxRealm Real of SIM not set For more details please check SIM Configuration","title":"Configure Splunk Infrastructure Monitoring Connection"},{"location":"gettingstarted/sc4snmp-installation/#install-sc4snmp","text":"microk8s helm3 install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace From now on, when editing SC4SNMP configuration, the configuration change must be inserted in the corresponding section of values.yaml . For more details check configuration section. Use the following command to propagate configuration changes: microk8s helm3 upgrade --install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace","title":"Install SC4SNMP"},{"location":"gettingstarted/sc4snmp-installation/#verify-deployment","text":"In a few minutes, all pods should be up and running. It can be verified with: microk8s kubectl get pods -n sc4snmp Example output: NAME READY STATUS RESTARTS AGE snmp - splunk - connect - for - snmp - worker - 66685 fcb6d - f6rxb 1 / 1 Running 0 6 m4s snmp - splunk - connect - for - snmp - scheduler - 6586488 d85 - t6j5d 1 / 1 Running 0 6 m4s snmp - mongodb - arbiter - 0 1 / 1 Running 0 6 m4s snmp - mibserver - 6 f575ddb7d - mmkmn 1 / 1 Running 0 6 m4s snmp - mongodb - 0 2 / 2 Running 0 6 m4s snmp - mongodb - 1 2 / 2 Running 0 4 m58s snmp - rabbitmq - 0 1 / 1 Running 0 6 m4s snmp - splunk - connect - for - snmp - traps - 54 f79b945d - bmbg7 1 / 1 Running 0 6 m4s","title":"Verify deployment"},{"location":"gettingstarted/sc4snmp-installation/#test-snmp-traps","text":"Test the Trap by logging into Splunk and confirming the presence of events in snmp netops and metrics in netmetrics index Test the trap from a Linux system with SNMP installed. Replace the IP address 10.0.101.22 with the shared IP address above apt update apt-get install snmpd snmptrap -v2c -c public 10 .0.101.22 123 1 .3.6.1.2.1.1.4 1 .3.6.1.2.1.1.4 s test Search Splunk: You should see one event per trap command with the host value of the test machine IP address index = \"netops\" sourcetype = \"sc4snmp:traps\"","title":"Test SNMP Traps"},{"location":"gettingstarted/sc4snmp-installation/#test-snmp-poller","text":"Test the Poller by logging into Splunk and confirming the presence of events in snmp netops and metrics in netmetrics index Test the trap from a Linux system install snmpd. apt update apt-get install snmpd To test SNMP poller, snmpd needs to be configured to listen on external IP. To enabled listening snmpd to external IP, in configuration file: /etc/snmp/snmpd.conf replace the IP address 10.0.101.22 with the server IP address where snmpd is configured agentaddress 10.0.101.22,127.0.0.1,[::1] . Restart snmpd by execute command: service snmpd stop service snmpd start Configure SC4SNMP Poller to test add IP address which need to be poll. Add configuration entry in value.yaml file by replace the IP address 10.0.101.22 with the server IP address where snmpd were configured. poller: usernameSecrets: - sc4snmp-homesecure-sha-aes - sc4snmp-homesecure-sha-des inventory: | address,version,community,walk_interval,profiles,SmartProfiles,delete 10 .0.101.22,public,60,,, Load value.yaml file in SC4SNMP microk8s helm3 upgrade --install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace Check-in Splunk Up to 1 min events appear in Splunk: index = \"netops\" sourcetype = \"sc4snmp:event\" Up to 1 min events appear in Splunk: | mpreview index = \"netmetrics\" | search sourcetype = \"sc4snmp:metric\"","title":"Test SNMP Poller"},{"location":"gettingstarted/sck-installation/","text":"Splunk OpenTelemetry Collector for Kubernetes installation \u00b6 The below steps are sufficient for a Splunk OpenTelemetry Collector installation for the SC4SNMP project with Splunk Enterprise/Enterprise Cloud. In order to learn more about Splunk OpenTelemetry Collector visit Splunk OpenTelemetry Collector . Add Splunk OpenTelemetry Collector repository to HELM \u00b6 microk8s helm3 repo add splunk-otel-collector-chart https://signalfx.github.io/splunk-otel-collector-chart Install Splunk OpenTelemetry Collector with HELM for a Splunk Platform \u00b6 In order to run Splunk OpenTelemetry Collector on your environment, replace <> variables according to the description presented below microk8s helm3 upgrade --install sck \\ --set = \"clusterName=<cluster_name>\" \\ --set = \"splunkPlatform.endpoint=<splunk_endpoint>\" \\ --set = \"splunkPlatform.insecureSkipVerify=<insecure_skip_verify>\" \\ --set = \"splunkPlatform.token=<splunk_token>\" \\ --set = \"logsEngine=otel\" \\ --set = \"splunkPlatform.metricsEnabled=true\" \\ --set = \"splunkPlatform.metricsIndex=em_metrics\" \\ --set = \"splunkPlatform.index=em_logs\" \\ splunk-otel-collector-chart/splunk-otel-collector Variables description \u00b6 Placeholder Description Example splunk_endpoint host address of splunk instance https://endpoint.example.com:8088/services/collector insecure_skip_verify is insecure ssl allowed false splunk_token Splunk HTTP Event Collector token 450a69af-16a9-4f87-9628-c26f04ad3785 cluster_name name of the cluster my-cluster An example of filled up command is: microk8s helm3 upgrade --install sck \\ --set = \"clusterName=my-cluster\" \\ --set = \"splunkPlatform.endpoint=https://endpoint.example.com/services/collector\" \\ --set = \"splunkPlatform.insecureSkipVerify=false\" \\ --set = \"splunkPlatform.token=4d22911c-18d9-4706-ae7b-dd1b976ca6f7\" \\ --set = \"splunkPlatform.metricsEnabled=true\" \\ --set = \"splunkPlatform.metricsIndex=em_metrics\" \\ --set = \"splunkPlatform.index=em_logs\" \\ splunk-otel-collector-chart/splunk-otel-collector Install Splunk OpenTelemetry Collector with HELM for Splunk Observability for Kubernetes \u00b6 To run Splunk OpenTelemetry Collector on your environment, replace <> variables according to the description presented below microk8s helm3 upgrade --install sck --set = \"clusterName=<cluster_name>\" --set = \"splunkObservability.realm=<realm>\" --set = \"splunkObservability.accessToken=<token>\" --set = \"splunkObservability.ingestUrl=<ingest_url>\" --set = \"splunkObservability.apiUrl=<api_url>\" --set = \"splunkObservability.metricsEnabled=true\" --set = \"splunkObservability.tracesEnabled=false\" --set = \"splunkObservability.logsEnabled=false\" splunk-otel-collector-chart/splunk-otel-collector Variables description \u00b6 Placeholder Description Example cluster_name name of the cluster my_cluster realm Realm obtained from the Splunk Observability Cloud environment us0 token Token obtained from the Splunk Observability Cloud environment BCwaJ_Ands4Xh7Nrg ingest_url Ingest URL from the Splunk Observability Cloud environment https://ingest..signalfx.com api_url API URL from the Splunk Observability Cloud environment https://api..signalfx.com An example of filled up command is: microk8s helm3 upgrade --install sck --set = \"clusterName=my_cluster\" --set = \"splunkObservability.realm=us0\" --set = \"splunkObservability.accessToken=BCwaJ_Ands4Xh7Nrg\" --set = \"splunkObservability.ingestUrl=https://ingest..signalfx.com\" --set = \"splunkObservability.apiUrl=https://api..signalfx.com\" --set = \"splunkObservability.metricsEnabled=true\" --set = \"splunkObservability.tracesEnabled=false\" --set = \"splunkObservability.logsEnabled=false\" splunk-otel-collector-chart/splunk-otel-collector","title":"Install Splunk OpenTelemetry Collector for Kubernetes"},{"location":"gettingstarted/sck-installation/#splunk-opentelemetry-collector-for-kubernetes-installation","text":"The below steps are sufficient for a Splunk OpenTelemetry Collector installation for the SC4SNMP project with Splunk Enterprise/Enterprise Cloud. In order to learn more about Splunk OpenTelemetry Collector visit Splunk OpenTelemetry Collector .","title":"Splunk OpenTelemetry Collector for Kubernetes installation"},{"location":"gettingstarted/sck-installation/#add-splunk-opentelemetry-collector-repository-to-helm","text":"microk8s helm3 repo add splunk-otel-collector-chart https://signalfx.github.io/splunk-otel-collector-chart","title":"Add Splunk OpenTelemetry Collector repository to HELM"},{"location":"gettingstarted/sck-installation/#install-splunk-opentelemetry-collector-with-helm-for-a-splunk-platform","text":"In order to run Splunk OpenTelemetry Collector on your environment, replace <> variables according to the description presented below microk8s helm3 upgrade --install sck \\ --set = \"clusterName=<cluster_name>\" \\ --set = \"splunkPlatform.endpoint=<splunk_endpoint>\" \\ --set = \"splunkPlatform.insecureSkipVerify=<insecure_skip_verify>\" \\ --set = \"splunkPlatform.token=<splunk_token>\" \\ --set = \"logsEngine=otel\" \\ --set = \"splunkPlatform.metricsEnabled=true\" \\ --set = \"splunkPlatform.metricsIndex=em_metrics\" \\ --set = \"splunkPlatform.index=em_logs\" \\ splunk-otel-collector-chart/splunk-otel-collector","title":"Install Splunk OpenTelemetry Collector with HELM for a Splunk Platform"},{"location":"gettingstarted/sck-installation/#variables-description","text":"Placeholder Description Example splunk_endpoint host address of splunk instance https://endpoint.example.com:8088/services/collector insecure_skip_verify is insecure ssl allowed false splunk_token Splunk HTTP Event Collector token 450a69af-16a9-4f87-9628-c26f04ad3785 cluster_name name of the cluster my-cluster An example of filled up command is: microk8s helm3 upgrade --install sck \\ --set = \"clusterName=my-cluster\" \\ --set = \"splunkPlatform.endpoint=https://endpoint.example.com/services/collector\" \\ --set = \"splunkPlatform.insecureSkipVerify=false\" \\ --set = \"splunkPlatform.token=4d22911c-18d9-4706-ae7b-dd1b976ca6f7\" \\ --set = \"splunkPlatform.metricsEnabled=true\" \\ --set = \"splunkPlatform.metricsIndex=em_metrics\" \\ --set = \"splunkPlatform.index=em_logs\" \\ splunk-otel-collector-chart/splunk-otel-collector","title":"Variables description"},{"location":"gettingstarted/sck-installation/#install-splunk-opentelemetry-collector-with-helm-for-splunk-observability-for-kubernetes","text":"To run Splunk OpenTelemetry Collector on your environment, replace <> variables according to the description presented below microk8s helm3 upgrade --install sck --set = \"clusterName=<cluster_name>\" --set = \"splunkObservability.realm=<realm>\" --set = \"splunkObservability.accessToken=<token>\" --set = \"splunkObservability.ingestUrl=<ingest_url>\" --set = \"splunkObservability.apiUrl=<api_url>\" --set = \"splunkObservability.metricsEnabled=true\" --set = \"splunkObservability.tracesEnabled=false\" --set = \"splunkObservability.logsEnabled=false\" splunk-otel-collector-chart/splunk-otel-collector","title":"Install Splunk OpenTelemetry Collector with HELM for Splunk Observability for Kubernetes"},{"location":"gettingstarted/sck-installation/#variables-description_1","text":"Placeholder Description Example cluster_name name of the cluster my_cluster realm Realm obtained from the Splunk Observability Cloud environment us0 token Token obtained from the Splunk Observability Cloud environment BCwaJ_Ands4Xh7Nrg ingest_url Ingest URL from the Splunk Observability Cloud environment https://ingest..signalfx.com api_url API URL from the Splunk Observability Cloud environment https://api..signalfx.com An example of filled up command is: microk8s helm3 upgrade --install sck --set = \"clusterName=my_cluster\" --set = \"splunkObservability.realm=us0\" --set = \"splunkObservability.accessToken=BCwaJ_Ands4Xh7Nrg\" --set = \"splunkObservability.ingestUrl=https://ingest..signalfx.com\" --set = \"splunkObservability.apiUrl=https://api..signalfx.com\" --set = \"splunkObservability.metricsEnabled=true\" --set = \"splunkObservability.tracesEnabled=false\" --set = \"splunkObservability.logsEnabled=false\" splunk-otel-collector-chart/splunk-otel-collector","title":"Variables description"},{"location":"gettingstarted/splunk-requirements/","text":"Splunk requirements \u00b6 Prepare Splunk \u00b6 Requirements (Splunk Enterprise/Enterprise Cloud) \u00b6 Manually create the following indexes in Splunk: Indexes for logs and metrics from SC4SNMP Connector: em_metrics (metrics type) em_logs (event type) Indexes where SNMP Data will be forwarded: netmetrics (metrics type) netops (event type) Note: netmetrics and netops are the default names of SC4SNMP indexes. You can use the index names of your choice and reference it in values.yaml file later on. Parameters and the instruction on how to do it is here: SC4SNMP Parameters Create or obtain a new Splunk HTTP Event Collector token and the correct HTTPS endpoint. Verify the token using curl Note: The endpoint must use a publicly trusted certificate authority. The SHARED IP address to be used for SNMP Traps. Note Simple and POC deployments will use the same IP as the host server. If HA deployment will be used, the IP must be in addition to the management interface of each cluster member. Obtain the IP address of an internal DNS server that can resolve the Splunk Endpoint. Requirements (Splunk Infrastructure Monitoring) \u00b6 Obtain the following from your Splunk Observability Cloud environment: Realm Token","title":"Splunk Requirements"},{"location":"gettingstarted/splunk-requirements/#splunk-requirements","text":"","title":"Splunk requirements"},{"location":"gettingstarted/splunk-requirements/#prepare-splunk","text":"","title":"Prepare Splunk"},{"location":"gettingstarted/splunk-requirements/#requirements-splunk-enterpriseenterprise-cloud","text":"Manually create the following indexes in Splunk: Indexes for logs and metrics from SC4SNMP Connector: em_metrics (metrics type) em_logs (event type) Indexes where SNMP Data will be forwarded: netmetrics (metrics type) netops (event type) Note: netmetrics and netops are the default names of SC4SNMP indexes. You can use the index names of your choice and reference it in values.yaml file later on. Parameters and the instruction on how to do it is here: SC4SNMP Parameters Create or obtain a new Splunk HTTP Event Collector token and the correct HTTPS endpoint. Verify the token using curl Note: The endpoint must use a publicly trusted certificate authority. The SHARED IP address to be used for SNMP Traps. Note Simple and POC deployments will use the same IP as the host server. If HA deployment will be used, the IP must be in addition to the management interface of each cluster member. Obtain the IP address of an internal DNS server that can resolve the Splunk Endpoint.","title":"Requirements (Splunk Enterprise/Enterprise Cloud)"},{"location":"gettingstarted/splunk-requirements/#requirements-splunk-infrastructure-monitoring","text":"Obtain the following from your Splunk Observability Cloud environment: Realm Token","title":"Requirements (Splunk Infrastructure Monitoring)"},{"location":"gettingstarted/mk8s/k8s-microk8s/","text":"Splunk Connect for SNMP using MicroK8s \u00b6 Using this deployment option any Linux deployment of Microk8s can be used to support SC4SNMP given the following requirements are met. The minimum requirements below are suitable for proof of value and small installations, actual requirements will differ. Single node minimum * 4 cores * 8 GB of memory per node * 50 GB mounted as / Three node minimum per node * 4 cores * 8 GB of memory per node * 50 GB mounted / MicroK8s installation on Ubuntu \u00b6 The following quick start guidance is based on Ubuntu 20.04LTS with MicroK8s with internet access. Other deployment options may be found in the MicroK8s documentation including offline and with proxy. Install MicroK8s using Snap \u00b6 sudo snap install microk8s --classic Add user to the microk8s group to no longer have to use the sudo command sudo usermod -a -G microk8s $USER sudo chown -f -R $USER ~/.kube su - $USER Wait for Installation of Mk8S to complete microk8s status --wait-ready Add additional nodes (optional) \u00b6 Repeat the steps above for each additional node (minimum total 3) On the first node issue the following, this will return joining instructions microk8s add-node On each additional node use the output from the command above Install basic services required for sc4snmp \u00b6 The following commands can be issued from any one node in a cluster sudo systemctl enable iscsid microk8s enable helm3 microk8s enable storage microk8s enable rbac microk8s enable community microk8s enable openebs microk8s status --wait-ready Install the DNS server for mk8s and configure the forwarding DNS servers replace the IP addressed below (opendns) from allowed values for your network microk8s enable dns:208.67.222.222,208.67.220.220 microk8s status --wait-ready Install Metallb \u00b6 Note: when installing metallb you will be prompted for one or more IPs to use as entry points Into the cluster. If your plan to enable clustering, this IP should not be assigned to the host (floats) If you do not plan to cluster, then this IP may be the same IP as the host Note2: a single IP in cidr format is x.x.x.x/32 use CIDR or range syntax for single server installations this can be the same as the primary ip. microk8s enable metallb microk8s status --wait-ready","title":"Platform Microk8s"},{"location":"gettingstarted/mk8s/k8s-microk8s/#splunk-connect-for-snmp-using-microk8s","text":"Using this deployment option any Linux deployment of Microk8s can be used to support SC4SNMP given the following requirements are met. The minimum requirements below are suitable for proof of value and small installations, actual requirements will differ. Single node minimum * 4 cores * 8 GB of memory per node * 50 GB mounted as / Three node minimum per node * 4 cores * 8 GB of memory per node * 50 GB mounted /","title":"Splunk Connect for SNMP using MicroK8s"},{"location":"gettingstarted/mk8s/k8s-microk8s/#microk8s-installation-on-ubuntu","text":"The following quick start guidance is based on Ubuntu 20.04LTS with MicroK8s with internet access. Other deployment options may be found in the MicroK8s documentation including offline and with proxy.","title":"MicroK8s installation on Ubuntu"},{"location":"gettingstarted/mk8s/k8s-microk8s/#install-microk8s-using-snap","text":"sudo snap install microk8s --classic Add user to the microk8s group to no longer have to use the sudo command sudo usermod -a -G microk8s $USER sudo chown -f -R $USER ~/.kube su - $USER Wait for Installation of Mk8S to complete microk8s status --wait-ready","title":"Install MicroK8s using Snap"},{"location":"gettingstarted/mk8s/k8s-microk8s/#add-additional-nodes-optional","text":"Repeat the steps above for each additional node (minimum total 3) On the first node issue the following, this will return joining instructions microk8s add-node On each additional node use the output from the command above","title":"Add additional nodes (optional)"},{"location":"gettingstarted/mk8s/k8s-microk8s/#install-basic-services-required-for-sc4snmp","text":"The following commands can be issued from any one node in a cluster sudo systemctl enable iscsid microk8s enable helm3 microk8s enable storage microk8s enable rbac microk8s enable community microk8s enable openebs microk8s status --wait-ready Install the DNS server for mk8s and configure the forwarding DNS servers replace the IP addressed below (opendns) from allowed values for your network microk8s enable dns:208.67.222.222,208.67.220.220 microk8s status --wait-ready","title":"Install basic services required for sc4snmp"},{"location":"gettingstarted/mk8s/k8s-microk8s/#install-metallb","text":"Note: when installing metallb you will be prompted for one or more IPs to use as entry points Into the cluster. If your plan to enable clustering, this IP should not be assigned to the host (floats) If you do not plan to cluster, then this IP may be the same IP as the host Note2: a single IP in cidr format is x.x.x.x/32 use CIDR or range syntax for single server installations this can be the same as the primary ip. microk8s enable metallb microk8s status --wait-ready","title":"Install Metallb"}]}
{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Splunk Connect for SNMP \u00b6 THIS IS BETA SOFTWARE Splunk welcomes your experimentation and feedback. Let your account team know you are testing Splunk Connect for SNMP. Splunk Connect for SNMP is an edge-deployed, containerized and highly available solution for collecting SNMP data for Splunk Enterprise, Splunk Enterprise Cloud and Splunk Infrastructure Monitoring.","title":"Home"},{"location":"#splunk-connect-for-snmp","text":"THIS IS BETA SOFTWARE Splunk welcomes your experimentation and feedback. Let your account team know you are testing Splunk Connect for SNMP. Splunk Connect for SNMP is an edge-deployed, containerized and highly available solution for collecting SNMP data for Splunk Enterprise, Splunk Enterprise Cloud and Splunk Infrastructure Monitoring.","title":"Splunk Connect for SNMP"},{"location":"configuration/","text":"Configuration \u00b6 In this section, we refer to these required files for configuring the scheduler: 1. scheduler-inventory.yaml 2. scheduler-config.yaml 3. traps-server-config.yaml When installing SC4SNMP via HELM, we can easily configure all these files from one point of management: values.yaml . The structure is: files : scheduler : inventory : | <- scheduler-inventory.yaml host,version,community,profile #10.0.0.1,2c,public,basev1 config : | <- scheduler-config.yaml celery: broker: type: \"rabbitmq\" # Sample Configuration file ipv4: True ipv6: False communities: ... traps : config : <- traps-server-config.yaml snmp : communities : v1 : - public - \"my-area\" v2 : - public - \"my-area\" When you addd modifications to any of yaml files, use the following command to propagate configuration changes: microk8s helm3 upgrade --install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace Traps Configuration \u00b6 traps-server-config.yaml config.yaml Splunk Connect for SNMP supports receiving SNMPv1 traps, SNMPv2 traps, and SNMPv3 traps. To use this functionality, configure using authorized SNMPv1/SNMPv2c community strings and/or SNMPv3 users in traps-server-config.yaml ( files.traps.config part of values.yaml ). Non-authorized traps/informs will not work. Configure SNMPv1/v2c community strings \u00b6 Add SNMPv1/SNMPv2c community strings under v1/v2 section, respectively. Params : community string (required) - SNMPv1/SNMPv2c community string. Configure SNMPv3 users \u00b6 It gets a little more complex with respect to SNMPv3. The user database in a SNMPv3 application is actually referenced by a combination of the user\u2019s name (called a \"security Name\") and an identifier for the given SNMP application you\u2019re talking to (called an \"engineID\"). Therefore, both userName and engineID are required for SNMPv3 under the v3 section. Params : userName (required) - A human-readable string representing the name of the SNMP USM user. authProtocol (optional) - An indication of whether messages sent on behalf of this USM user can be authenticated, and if so, the type of authentication protocol that is used. If both authKey and authProtocol are not set, usmNoAuthProtocol is implied. If authKey is set and no authProtocol is specified, usmHMACMD5AuthProtocol takes effect. Supported authentication protocol identifiers are: None (default is authKey not given) MD5 (default if authKey is given) SHA SHA224 SHA256 SHA512 authKey (optional) - Initial value of the secret authentication key. privProtocol (optional) - An indication of whether messages sent on behalf of this USM user are encrypted, and if so, the type of encryption protocol that is used. If both privKey and privProtocol are not set, usmNoPrivProtocol is implied. If privKey is set and no privProtocol is specified, usmDESPrivProtocol takes effect. Supported encryption protocol identifiers are: None (default is privhKey not given) DES (default if privKey is given) 3DES AES AES128 AES192 AES192BLMT AES256 AES256BLMT privKey (optional) - Initial value of the secret encryption key. securityEngineId (required): The EngineID of the authoritative SNMP engine that the traps were sent from. e.g. snmp : communities : v1 : - public - \"my-area\" v2 : - public - \"my-area\" v3 : - userName : snmpv3test authKey : AuthPass1 privKey : PrivPass2 securityEngineId : 8000000004030201 - userName : snmpv3test2 authProtocol : SHA authKey : AuthPass11 privProtocol : aes privKey : PrivPass22 securityEngineId : 8000000004030202 - userName : snmpv3test3 securityEngineId : 8000000004030203 Poller \u00b6 Scheduler Configuration \u00b6 scheduler-config.yaml config.yaml scheduler-inventory.yaml inventory.csv Splunk Connect for SNMP supports polling from SNMPv1 agents, SNMPv2 agents, and SNMPv3 agents. To use this functionality, configure using authorized SNMPv1/SNMPv2c community strings and/or SNMPv3 users in scheduler-config.yaml ( files.scheduler.config part of values.yaml ). inventory.csv \u00b6 Inventory.csv ( files.scheduler.inventory part of values.yaml ) acts as a lookup table where the poller application will read the SNMP agents\u2019 information and its corresponding query information. \" host \" , \" version \" , \" community \" , \" profile \" \" IP:Port of SNMP agents, where port is optional with default of 161 \" , \" An indication of SNMP versions \" , \" community string for SNMPv1/v2 OR userName for SNMPv3 \" , \" query info \" \"e.g. 174.62.79.72 (IP only) | 174.62.79.72:161 (IP+port)\",\"e.g. 1 | 2c | 3\", \"e.g. public (SNMPv1/SNMPv2c community string) | testUser (SNMPv3 username, setup other params in config.yaml)\",| router (profile used to setup detials in config.yaml\" config.yaml \u00b6 config.yaml acts as an extension for inventory.csv for these three situations. args \u00b6 There are 4 parameters to be configured in values.yaml : 1. refresh_interval - indicates how often (in seconds) we monitor changes on inventory.csv and config.yaml 2. realtime_task_frequency - indicates how often (in seconds) we check if any of the monitored devices were restarted 3. matching_task_frequency - indicates how often (in seconds) dynamic profiles are matched for a host (specified in inventory with an \u201c*\u201d in profile column) 4. onetime_task_frequency - indicates how often (in seconds) one time walk (walk of whole OID tree 1.3.6.1) will be triggered after the fail. 1. Configure optional parameters for SNMPv1/SNMPv2c community data \u00b6 Community-Based Security Model of SNMPv1/SNMPv2c may require more parameters, which can be set up in config.yaml ( files.scheduler.config part of values.yaml ). Add SNMPv1/SNMPv2c community string as Key under the communities section. Add necessary parameters. Here are supported optional parameters: communityIndex (optional) - Unique index value of a row in snmpCommunityTable. If it is the only positional parameter, it is treated as a communityName. contextEngineId (optional) - Indicates the location of the context in which management information is accessed when using the community string specified by the communityName. contextName (optional) - The context in which management information is accessed when using the above communityName. tag (optional) - Arbitrary string that specifies a set of transport endpoints from which a command responder application will accept management requests with a given communityName or to which notification originator application will send notifications when targets are specified by a tag value(s). 2. Configure optional parameters SNMPv3 users \u00b6 SNMPv3 users may require more parameters for different security levels, which can be set up in config.yaml ( files.scheduler.config part of values.yaml ). Add SNMPv3 userName as Key under usernames section. Add necessary parameters. Here are supported optional parameters: authKey (optional) - Initial value of the secret authentication key. authProtocol (optional) - An indication of whether messages sent on behalf of this USM user can be authenticated, and if so, the type of authentication protocol that is used. If both authKey and authProtocol are not set, usmNoAuthProtocol is implied. If authKey is set and no authProtocol is specified, usmHMACMD5AuthProtocol takes effect. Supported authentication protocol identifiers are: None (default is authKey not given) MD5 (default if authKey is given) SHA SHA224 SHA256 SHA512 privKey (optional) - Initial value of the secret encryption key. privProtocol (optional) - An indication of whether messages sent on behalf of this USM user be encrypted, and if so, the type of encryption protocol that is used. If both privKey and privProtocol are not set, usmNoPrivProtocol is implied. If privKey is set and no privProtocol is specified, usmDESPrivProtocol takes effect. Supported encryption protocol identifiers are: None (default is privhKey not given) DES (default if privKey is given) 3DES AES AES128 AES192 AES192BLMT AES256 AES256BLMT securityEngineId (optional): The snmpEngineID of the authoritative SNMP engine to which a dateRequest message is to be sent. securityName (optional): Along with the snmpEngineID, it identifies a row in the SNMP-USER-BASED-SM-MIB::usmUserTable that is to be used for securing the message. authKeyType (optional): int. Type of authKey material. privKeyType (optional): int. Type of privKey material. contextName : (optional) contextName is used to name an instance of MIB. SNMP engine may serve several instances of the same MIB within possibly multiple SNMP entities. SNMP context is a tool for unambiguously identifying a collection of MIB variables behind the SNMP engine. e.g. usernames : testUser1 : authKey : auctoritas privKey : privatus testUser2 : authKey : testauthKey privKey : testprivKey authProtocol : SHA privProtocol : AES securityEngineId : 8000000004030201 securityName : authKeyType : 0 privKeyType : 0 contextName : \"4c9184f37cff01bcdc32dc486ec36961\" 3. Configure more detailed query information \u00b6 Users can provide query information under the profiles section to achieve two purposes: 1) query by mib string; 2) query multiple oids/mib string for one agent. In scheduler-inventory.yaml ( files.scheduler.inventory part of values.yaml ), add the profile string(e.g. router) to the profile field under data > inventory.csv section. \"host\", \"version\", \"community\", \"profile\" 10.42.0.58,1,public,router In scheduler-config.yaml ( files.scheduler.config part of values.yaml ), add the desired query information under the profiles > \\ > varBinds section as list entries. e.g. profiles > router > varBinds . When you use the mib string, you MUST follow the Syntax below [ \"MIB-Files\" , \"MIB object name\" , \"MIB index number\" ] Where \u201cMIB index number\u201d is optional. Specify the index number when you want to get the information for a specific interface. e.g. [\"SNMPv2-MIB\", \"sysUpTime\", 0] Don\u2019t specify the index number when you want to get information for all interfaces. e.g. [\"SNMPv2-MIB\", \"sysORID\"] Note : A wrong index number would cause an error. If you are not sure which index exists, don\u2019t put it at all. For example, in the situation where [\"SNMPv2-MIB\", \"sysUpTime\", 0] exsits, both [\"SNMPv2-MIB\", \"sysUpTime\", 0] and [\"SNMPv2-MIB\", \"sysUpTime\"] will help you get [\"SNMPv2-MIB\", \"sysUpTime\", 0], while [\"SNMPv2-MIB\", \"sysUpTime\", 1] will throw error because index 1 doesn't exist for sysUpTime. profiles : router : varBinds : # Syntax: [ \"MIB-Files\", \"MIB object name\", \"MIB index number\"] - [ 'SNMPv2-MIB' , 'sysDescr' , 0 ] - [ 'SNMPv2-MIB' , 'sysUpTime' , 0 ] - [ 'SNMPv2-MIB' , 'sysORID' ] - [ 'CISCO-FC-MGMT-MIB' , 'cfcmPortLcStatsEntry' ] - [ 'EFM-CU-MIB' , 'efmCuPort' ] - '1.3.6.1.2.1.1.6.0' - '1.3.6.1.2.1.1.9.1.4.*' 4. Configure additional field to the metrics data \u00b6 Users can make every metric data include a profile name (which is not included by default) by adding profile under the additionalMetricField in scheduler-config.yaml ( files.scheduler.config part of values.yaml ) e.g. additionalMetricField : - profile 5. Configure poller to return query with additional fields present \u00b6 Users can add an enricher section to make poller enrich queries sent to Splunk by adding additional dimensions 1. existingVarBinds : this section updates query results with new fields calculated from the existing SNMP information. Existing VarBinds \u00b6 For now, existingVarBinds section works only for IF-MIB oid family. Every property of IF-MIB family can be extracted and added as an additional dimension to the query. For example, if we want to see the name and the index of the interface along with the basic query information, the enricher must be structured as follows: files : scheduler : config : enricherIfMib : - ifIndex : 'interface_index' - ifDescr : 'interface_desc' Let\u2019s run a metrics query in Splunk Search: | msearch \"index\"=\"em_metrics\" While enricher is not being used, the example result is: { [ - ] com.splunk.index : em_metrics host.name : 10.202.14.102 metric_name : sc4snmp.IF-MIB.ifInOctets_1 : 398485 } After adding the enricher structure as noted above, the same result should contain \u201cinterface_index\u201d and \u201cinterface_desc\u201d: { [ - ] com.splunk.index : em_metrics host.name : 10.202.14.102 interface_desc : lo interface_index : 1 metric_name : sc4snmp.IF-MIB.ifInOctets_1 : 398485 } For an event query in Splunk Search: index=\"*\" sourcetype=\"sc4snmp:meta\" Before using enricher , the search result is structured as following: oid-type1=\"ObjectIdentity\" value1-type=\"OctetString\" 1.3.6.1.2.1.2.2.1.6.2=\"0x00127962f940\" value1=\"0x00127962f940\" IF-MIB::ifPhysAddress.2=\"12:79:62:f9:40\" When using the same enricher as in the example above, in the result string two new fields \u201cinterface_index\u201d and \u201cinterface_desc\u201d are visible: oid-type1=\"ObjectIdentity\" value1-type=\"OctetString\" 1.3.6.1.2.1.2.2.1.6.2=\"0x00127962f940\" value1=\"0x00127962f940\" IF-MIB::ifPhysAddress.2=\"12:79:62:f9:40\" interface_index=\"2\" interface_desc=\"eth0\" The value of newly added properties is calculated according to current query index. For IF-MIB::ifAdminStatus. 2 we\u2019re interested in IF-MIB::ifIndex. 2 and IF-MIB::ifDescr. 2 . IF-MIB::ifNumber.0 = INTEGER : 2 IF-MIB::ifIndex.1 = INTEGER : 1 IF-MIB::ifIndex.2 = INTEGER : 2 IF-MIB::ifDescr.1 = STRING : lo IF-MIB::ifDescr.2 = STRING : eth0 Any other IF-MIB property can be inserted to existingVarBinds. existingVarBinds list parameters existingVarBinds part description example key the key is the word between OID family identifier and the index for ex. for physical address, the key is ifPhysAddress (derived from IF-MIB:: ifPhysAddress .1) value the field name shown as an additional dimension in Splunk physical_address Note: values that are going to be used as additional dimensions are gathered during SNMP Walk operation after enricher configuration. That means that they\u2019re static, and they won\u2019t get updated even if its value changes on the device. Please use static values with enricher (like ifDescr, ifIndex or IfSpeed). Test the poller \u00b6 SNMPv1/SNMPv2 You can change the inventory contents in scheduler-config.yaml ( files.scheduler.config part of values.yaml ) and use the following command to apply the changes to the Kubernetes cluster. Agents configuration is placed in scheduler-config.yaml under the section inventory.csv , and the content below is interpreted as a .csv file with following columns: host (IP or name) version of SNMP protocol community string authorisation phrase profile of device (varBinds of profiles can be found in files.scheduler.config part of values.yaml ) Note that profile must be first created in files.scheduler.config , for example: profiles : router : frequency : 20 varBinds : - 1.3.6.1.2.1.1.9.1.3.* - [ 'SNMPv2-MIB' , 'sysUpTime' , 0 ] - [ 'SNMPv2-MIB' , 'sysName' ] Under files.scheduler.inventory put the line: \"host\", \"version\", \"community\", \"profile\" 10.42.0.58,1,public,router host.docker.internal,2c,public,router Where 10.42.0.58 is an IP address of a device running SNMP. Use below command to update SC4SNMP with the changes you\u2019ve made: microk8s helm3 upgrade --install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace SNMPv3 Besides changing the inventory contents under the section files.scheduler.inventory part of values.yaml , you may need to set up security passphrases for the SNMPv3 under the section files.scheduler.config.usernames part of values.yaml . Here are the steps to configure these two SNMPv3 Users. User Name Security Auth Priv Auth Priv Level Protocol Protocol Passphrase Passphrase testUser1 Auth,Priv MD5 DES auctoritas privatus testUser2 Auth,Priv SHA AES authpass privacypass Specify User Name under community filed in section files.scheduler.inventory part of values.yaml . \"host\", \"version\", \"community\", \"profile\" host.docker.internal1,3,testUser1,router host.docker.internal2,3,testUser2,profile_name Specify other security parameters under section files.scheduler.config part of values.yaml . usernames : testUser1 : authKey : auctoritas privKey : privatus testUser2 : authKey : authpass privKey : privacypass authProtocol : SHA privProtocol : AES Apply the changes. microk8s helm3 upgrade --install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace Workflow of the SC4SNMP \u00b6 Everytime you add a new host to the files.scheduler.inventory , one time walk is scheduled for it. This serves for gathering useful information about the device, like: 1. uptime of the sys tem , so then we know if device was restarted and we need to refresh the data base 2. sys tem description and object id , that helps to match patterns for dynamic profile matching In case first one time walk was unsuccessful (fo ex. we couldn\u2019t connect to the device), another onetime walk will be triggered after the time specified in files.scheduler.args.onetime_task_frequency . In case you want to enrich IF-MIB OID family, every newly added job will trigger a small WALK only for IF-MIB OID family -> 1.3.6.1.2.1.2.* .","title":"Configuration"},{"location":"configuration/#configuration","text":"In this section, we refer to these required files for configuring the scheduler: 1. scheduler-inventory.yaml 2. scheduler-config.yaml 3. traps-server-config.yaml When installing SC4SNMP via HELM, we can easily configure all these files from one point of management: values.yaml . The structure is: files : scheduler : inventory : | <- scheduler-inventory.yaml host,version,community,profile #10.0.0.1,2c,public,basev1 config : | <- scheduler-config.yaml celery: broker: type: \"rabbitmq\" # Sample Configuration file ipv4: True ipv6: False communities: ... traps : config : <- traps-server-config.yaml snmp : communities : v1 : - public - \"my-area\" v2 : - public - \"my-area\" When you addd modifications to any of yaml files, use the following command to propagate configuration changes: microk8s helm3 upgrade --install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace","title":"Configuration"},{"location":"configuration/#traps-configuration","text":"traps-server-config.yaml config.yaml Splunk Connect for SNMP supports receiving SNMPv1 traps, SNMPv2 traps, and SNMPv3 traps. To use this functionality, configure using authorized SNMPv1/SNMPv2c community strings and/or SNMPv3 users in traps-server-config.yaml ( files.traps.config part of values.yaml ). Non-authorized traps/informs will not work.","title":"Traps Configuration"},{"location":"configuration/#configure-snmpv1v2c-community-strings","text":"Add SNMPv1/SNMPv2c community strings under v1/v2 section, respectively. Params : community string (required) - SNMPv1/SNMPv2c community string.","title":"Configure SNMPv1/v2c community strings"},{"location":"configuration/#configure-snmpv3-users","text":"It gets a little more complex with respect to SNMPv3. The user database in a SNMPv3 application is actually referenced by a combination of the user\u2019s name (called a \"security Name\") and an identifier for the given SNMP application you\u2019re talking to (called an \"engineID\"). Therefore, both userName and engineID are required for SNMPv3 under the v3 section. Params : userName (required) - A human-readable string representing the name of the SNMP USM user. authProtocol (optional) - An indication of whether messages sent on behalf of this USM user can be authenticated, and if so, the type of authentication protocol that is used. If both authKey and authProtocol are not set, usmNoAuthProtocol is implied. If authKey is set and no authProtocol is specified, usmHMACMD5AuthProtocol takes effect. Supported authentication protocol identifiers are: None (default is authKey not given) MD5 (default if authKey is given) SHA SHA224 SHA256 SHA512 authKey (optional) - Initial value of the secret authentication key. privProtocol (optional) - An indication of whether messages sent on behalf of this USM user are encrypted, and if so, the type of encryption protocol that is used. If both privKey and privProtocol are not set, usmNoPrivProtocol is implied. If privKey is set and no privProtocol is specified, usmDESPrivProtocol takes effect. Supported encryption protocol identifiers are: None (default is privhKey not given) DES (default if privKey is given) 3DES AES AES128 AES192 AES192BLMT AES256 AES256BLMT privKey (optional) - Initial value of the secret encryption key. securityEngineId (required): The EngineID of the authoritative SNMP engine that the traps were sent from. e.g. snmp : communities : v1 : - public - \"my-area\" v2 : - public - \"my-area\" v3 : - userName : snmpv3test authKey : AuthPass1 privKey : PrivPass2 securityEngineId : 8000000004030201 - userName : snmpv3test2 authProtocol : SHA authKey : AuthPass11 privProtocol : aes privKey : PrivPass22 securityEngineId : 8000000004030202 - userName : snmpv3test3 securityEngineId : 8000000004030203","title":"Configure SNMPv3 users"},{"location":"configuration/#poller","text":"","title":"Poller"},{"location":"configuration/#scheduler-configuration","text":"scheduler-config.yaml config.yaml scheduler-inventory.yaml inventory.csv Splunk Connect for SNMP supports polling from SNMPv1 agents, SNMPv2 agents, and SNMPv3 agents. To use this functionality, configure using authorized SNMPv1/SNMPv2c community strings and/or SNMPv3 users in scheduler-config.yaml ( files.scheduler.config part of values.yaml ).","title":"Scheduler Configuration"},{"location":"configuration/#inventorycsv","text":"Inventory.csv ( files.scheduler.inventory part of values.yaml ) acts as a lookup table where the poller application will read the SNMP agents\u2019 information and its corresponding query information. \" host \" , \" version \" , \" community \" , \" profile \" \" IP:Port of SNMP agents, where port is optional with default of 161 \" , \" An indication of SNMP versions \" , \" community string for SNMPv1/v2 OR userName for SNMPv3 \" , \" query info \" \"e.g. 174.62.79.72 (IP only) | 174.62.79.72:161 (IP+port)\",\"e.g. 1 | 2c | 3\", \"e.g. public (SNMPv1/SNMPv2c community string) | testUser (SNMPv3 username, setup other params in config.yaml)\",| router (profile used to setup detials in config.yaml\"","title":"inventory.csv"},{"location":"configuration/#configyaml","text":"config.yaml acts as an extension for inventory.csv for these three situations.","title":"config.yaml"},{"location":"configuration/#args","text":"There are 4 parameters to be configured in values.yaml : 1. refresh_interval - indicates how often (in seconds) we monitor changes on inventory.csv and config.yaml 2. realtime_task_frequency - indicates how often (in seconds) we check if any of the monitored devices were restarted 3. matching_task_frequency - indicates how often (in seconds) dynamic profiles are matched for a host (specified in inventory with an \u201c*\u201d in profile column) 4. onetime_task_frequency - indicates how often (in seconds) one time walk (walk of whole OID tree 1.3.6.1) will be triggered after the fail.","title":"args"},{"location":"configuration/#1-configure-optional-parameters-for-snmpv1snmpv2c-community-data","text":"Community-Based Security Model of SNMPv1/SNMPv2c may require more parameters, which can be set up in config.yaml ( files.scheduler.config part of values.yaml ). Add SNMPv1/SNMPv2c community string as Key under the communities section. Add necessary parameters. Here are supported optional parameters: communityIndex (optional) - Unique index value of a row in snmpCommunityTable. If it is the only positional parameter, it is treated as a communityName. contextEngineId (optional) - Indicates the location of the context in which management information is accessed when using the community string specified by the communityName. contextName (optional) - The context in which management information is accessed when using the above communityName. tag (optional) - Arbitrary string that specifies a set of transport endpoints from which a command responder application will accept management requests with a given communityName or to which notification originator application will send notifications when targets are specified by a tag value(s).","title":"1. Configure optional parameters for SNMPv1/SNMPv2c community data"},{"location":"configuration/#2-configure-optional-parameters-snmpv3-users","text":"SNMPv3 users may require more parameters for different security levels, which can be set up in config.yaml ( files.scheduler.config part of values.yaml ). Add SNMPv3 userName as Key under usernames section. Add necessary parameters. Here are supported optional parameters: authKey (optional) - Initial value of the secret authentication key. authProtocol (optional) - An indication of whether messages sent on behalf of this USM user can be authenticated, and if so, the type of authentication protocol that is used. If both authKey and authProtocol are not set, usmNoAuthProtocol is implied. If authKey is set and no authProtocol is specified, usmHMACMD5AuthProtocol takes effect. Supported authentication protocol identifiers are: None (default is authKey not given) MD5 (default if authKey is given) SHA SHA224 SHA256 SHA512 privKey (optional) - Initial value of the secret encryption key. privProtocol (optional) - An indication of whether messages sent on behalf of this USM user be encrypted, and if so, the type of encryption protocol that is used. If both privKey and privProtocol are not set, usmNoPrivProtocol is implied. If privKey is set and no privProtocol is specified, usmDESPrivProtocol takes effect. Supported encryption protocol identifiers are: None (default is privhKey not given) DES (default if privKey is given) 3DES AES AES128 AES192 AES192BLMT AES256 AES256BLMT securityEngineId (optional): The snmpEngineID of the authoritative SNMP engine to which a dateRequest message is to be sent. securityName (optional): Along with the snmpEngineID, it identifies a row in the SNMP-USER-BASED-SM-MIB::usmUserTable that is to be used for securing the message. authKeyType (optional): int. Type of authKey material. privKeyType (optional): int. Type of privKey material. contextName : (optional) contextName is used to name an instance of MIB. SNMP engine may serve several instances of the same MIB within possibly multiple SNMP entities. SNMP context is a tool for unambiguously identifying a collection of MIB variables behind the SNMP engine. e.g. usernames : testUser1 : authKey : auctoritas privKey : privatus testUser2 : authKey : testauthKey privKey : testprivKey authProtocol : SHA privProtocol : AES securityEngineId : 8000000004030201 securityName : authKeyType : 0 privKeyType : 0 contextName : \"4c9184f37cff01bcdc32dc486ec36961\"","title":"2. Configure optional parameters SNMPv3 users"},{"location":"configuration/#3-configure-more-detailed-query-information","text":"Users can provide query information under the profiles section to achieve two purposes: 1) query by mib string; 2) query multiple oids/mib string for one agent. In scheduler-inventory.yaml ( files.scheduler.inventory part of values.yaml ), add the profile string(e.g. router) to the profile field under data > inventory.csv section. \"host\", \"version\", \"community\", \"profile\" 10.42.0.58,1,public,router In scheduler-config.yaml ( files.scheduler.config part of values.yaml ), add the desired query information under the profiles > \\ > varBinds section as list entries. e.g. profiles > router > varBinds . When you use the mib string, you MUST follow the Syntax below [ \"MIB-Files\" , \"MIB object name\" , \"MIB index number\" ] Where \u201cMIB index number\u201d is optional. Specify the index number when you want to get the information for a specific interface. e.g. [\"SNMPv2-MIB\", \"sysUpTime\", 0] Don\u2019t specify the index number when you want to get information for all interfaces. e.g. [\"SNMPv2-MIB\", \"sysORID\"] Note : A wrong index number would cause an error. If you are not sure which index exists, don\u2019t put it at all. For example, in the situation where [\"SNMPv2-MIB\", \"sysUpTime\", 0] exsits, both [\"SNMPv2-MIB\", \"sysUpTime\", 0] and [\"SNMPv2-MIB\", \"sysUpTime\"] will help you get [\"SNMPv2-MIB\", \"sysUpTime\", 0], while [\"SNMPv2-MIB\", \"sysUpTime\", 1] will throw error because index 1 doesn't exist for sysUpTime. profiles : router : varBinds : # Syntax: [ \"MIB-Files\", \"MIB object name\", \"MIB index number\"] - [ 'SNMPv2-MIB' , 'sysDescr' , 0 ] - [ 'SNMPv2-MIB' , 'sysUpTime' , 0 ] - [ 'SNMPv2-MIB' , 'sysORID' ] - [ 'CISCO-FC-MGMT-MIB' , 'cfcmPortLcStatsEntry' ] - [ 'EFM-CU-MIB' , 'efmCuPort' ] - '1.3.6.1.2.1.1.6.0' - '1.3.6.1.2.1.1.9.1.4.*'","title":"3. Configure more detailed query information"},{"location":"configuration/#4-configure-additional-field-to-the-metrics-data","text":"Users can make every metric data include a profile name (which is not included by default) by adding profile under the additionalMetricField in scheduler-config.yaml ( files.scheduler.config part of values.yaml ) e.g. additionalMetricField : - profile","title":"4. Configure additional field to the metrics data"},{"location":"configuration/#5-configure-poller-to-return-query-with-additional-fields-present","text":"Users can add an enricher section to make poller enrich queries sent to Splunk by adding additional dimensions 1. existingVarBinds : this section updates query results with new fields calculated from the existing SNMP information.","title":"5. Configure poller to return query with additional fields present"},{"location":"configuration/#existing-varbinds","text":"For now, existingVarBinds section works only for IF-MIB oid family. Every property of IF-MIB family can be extracted and added as an additional dimension to the query. For example, if we want to see the name and the index of the interface along with the basic query information, the enricher must be structured as follows: files : scheduler : config : enricherIfMib : - ifIndex : 'interface_index' - ifDescr : 'interface_desc' Let\u2019s run a metrics query in Splunk Search: | msearch \"index\"=\"em_metrics\" While enricher is not being used, the example result is: { [ - ] com.splunk.index : em_metrics host.name : 10.202.14.102 metric_name : sc4snmp.IF-MIB.ifInOctets_1 : 398485 } After adding the enricher structure as noted above, the same result should contain \u201cinterface_index\u201d and \u201cinterface_desc\u201d: { [ - ] com.splunk.index : em_metrics host.name : 10.202.14.102 interface_desc : lo interface_index : 1 metric_name : sc4snmp.IF-MIB.ifInOctets_1 : 398485 } For an event query in Splunk Search: index=\"*\" sourcetype=\"sc4snmp:meta\" Before using enricher , the search result is structured as following: oid-type1=\"ObjectIdentity\" value1-type=\"OctetString\" 1.3.6.1.2.1.2.2.1.6.2=\"0x00127962f940\" value1=\"0x00127962f940\" IF-MIB::ifPhysAddress.2=\"12:79:62:f9:40\" When using the same enricher as in the example above, in the result string two new fields \u201cinterface_index\u201d and \u201cinterface_desc\u201d are visible: oid-type1=\"ObjectIdentity\" value1-type=\"OctetString\" 1.3.6.1.2.1.2.2.1.6.2=\"0x00127962f940\" value1=\"0x00127962f940\" IF-MIB::ifPhysAddress.2=\"12:79:62:f9:40\" interface_index=\"2\" interface_desc=\"eth0\" The value of newly added properties is calculated according to current query index. For IF-MIB::ifAdminStatus. 2 we\u2019re interested in IF-MIB::ifIndex. 2 and IF-MIB::ifDescr. 2 . IF-MIB::ifNumber.0 = INTEGER : 2 IF-MIB::ifIndex.1 = INTEGER : 1 IF-MIB::ifIndex.2 = INTEGER : 2 IF-MIB::ifDescr.1 = STRING : lo IF-MIB::ifDescr.2 = STRING : eth0 Any other IF-MIB property can be inserted to existingVarBinds. existingVarBinds list parameters existingVarBinds part description example key the key is the word between OID family identifier and the index for ex. for physical address, the key is ifPhysAddress (derived from IF-MIB:: ifPhysAddress .1) value the field name shown as an additional dimension in Splunk physical_address Note: values that are going to be used as additional dimensions are gathered during SNMP Walk operation after enricher configuration. That means that they\u2019re static, and they won\u2019t get updated even if its value changes on the device. Please use static values with enricher (like ifDescr, ifIndex or IfSpeed).","title":"Existing VarBinds"},{"location":"configuration/#test-the-poller","text":"SNMPv1/SNMPv2 You can change the inventory contents in scheduler-config.yaml ( files.scheduler.config part of values.yaml ) and use the following command to apply the changes to the Kubernetes cluster. Agents configuration is placed in scheduler-config.yaml under the section inventory.csv , and the content below is interpreted as a .csv file with following columns: host (IP or name) version of SNMP protocol community string authorisation phrase profile of device (varBinds of profiles can be found in files.scheduler.config part of values.yaml ) Note that profile must be first created in files.scheduler.config , for example: profiles : router : frequency : 20 varBinds : - 1.3.6.1.2.1.1.9.1.3.* - [ 'SNMPv2-MIB' , 'sysUpTime' , 0 ] - [ 'SNMPv2-MIB' , 'sysName' ] Under files.scheduler.inventory put the line: \"host\", \"version\", \"community\", \"profile\" 10.42.0.58,1,public,router host.docker.internal,2c,public,router Where 10.42.0.58 is an IP address of a device running SNMP. Use below command to update SC4SNMP with the changes you\u2019ve made: microk8s helm3 upgrade --install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace SNMPv3 Besides changing the inventory contents under the section files.scheduler.inventory part of values.yaml , you may need to set up security passphrases for the SNMPv3 under the section files.scheduler.config.usernames part of values.yaml . Here are the steps to configure these two SNMPv3 Users. User Name Security Auth Priv Auth Priv Level Protocol Protocol Passphrase Passphrase testUser1 Auth,Priv MD5 DES auctoritas privatus testUser2 Auth,Priv SHA AES authpass privacypass Specify User Name under community filed in section files.scheduler.inventory part of values.yaml . \"host\", \"version\", \"community\", \"profile\" host.docker.internal1,3,testUser1,router host.docker.internal2,3,testUser2,profile_name Specify other security parameters under section files.scheduler.config part of values.yaml . usernames : testUser1 : authKey : auctoritas privKey : privatus testUser2 : authKey : authpass privKey : privacypass authProtocol : SHA privProtocol : AES Apply the changes. microk8s helm3 upgrade --install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace","title":"Test the poller"},{"location":"configuration/#workflow-of-the-sc4snmp","text":"Everytime you add a new host to the files.scheduler.inventory , one time walk is scheduled for it. This serves for gathering useful information about the device, like: 1. uptime of the sys tem , so then we know if device was restarted and we need to refresh the data base 2. sys tem description and object id , that helps to match patterns for dynamic profile matching In case first one time walk was unsuccessful (fo ex. we couldn\u2019t connect to the device), another onetime walk will be triggered after the time specified in files.scheduler.args.onetime_task_frequency . In case you want to enrich IF-MIB OID family, every newly added job will trigger a small WALK only for IF-MIB OID family -> 1.3.6.1.2.1.2.* .","title":"Workflow of the SC4SNMP"},{"location":"planning/","text":"Planning \u00b6 Splunk Connect for SNMP (SC4SNMP) is a solution that allows the customer to \"get\" data from network devices and appliances when a more feature-complete solution, such as the Splunk Universal Forwarder, is not available. Architecture \u00b6 SC4SNMP is deployed using a Kubernetes distribution, typically MicroK8s, that\u2019s deseigned to be a low-touch experience for integration with sensitive edge network devices. It will typically be deployed in the same network management zone as the monitored devices and seperated from Splunk by an existing firewall. Requirements \u00b6 A supported deployment of MicroK8s 16 Core/32 threads x64 architecture server or vm (single instance) 12 GB ram HA Requires 3 or more instances (odd numbers) 8 core/16 thread 16 GB ram 100 GB root mount http access (non proxy) allowed for the HTTP(s) connection from SC4SNMP to the Splunk destination. Splunk Enterprise/Cloud 8.x and or Splunk Infrastructure Monitoring (SignalFX) Splunk Enterprise/Cloud specific Requirements : - Splunk ITSI or Splunk IT Work - Ability to create a HEC token - Ability to create event and metrics indexes (or use existing) Splunk Infrastructure Monitoring specific requirements : - Ability to create or obtain real and token Planning Infrastructure \u00b6 Single installation of Splunk Connect for SNMP (SC4SNMP) on a machine with 16 Core/32 threads x64 and 12 GB ram will be able to handle up to 1300 SNMP TRAPs per sec. Single installation of Splunk Connect for SNMP (SC4SNMP) on a machine with 16 Core/32 threads x64 and 64 GB ram will be able to handle up to 1300 SNMP GETs per sec. When planning infrastructure for Splunk Connect for SNMP, (SC4SNMP) note the limitations highlighted above.","title":"Planning"},{"location":"planning/#planning","text":"Splunk Connect for SNMP (SC4SNMP) is a solution that allows the customer to \"get\" data from network devices and appliances when a more feature-complete solution, such as the Splunk Universal Forwarder, is not available.","title":"Planning"},{"location":"planning/#architecture","text":"SC4SNMP is deployed using a Kubernetes distribution, typically MicroK8s, that\u2019s deseigned to be a low-touch experience for integration with sensitive edge network devices. It will typically be deployed in the same network management zone as the monitored devices and seperated from Splunk by an existing firewall.","title":"Architecture"},{"location":"planning/#requirements","text":"A supported deployment of MicroK8s 16 Core/32 threads x64 architecture server or vm (single instance) 12 GB ram HA Requires 3 or more instances (odd numbers) 8 core/16 thread 16 GB ram 100 GB root mount http access (non proxy) allowed for the HTTP(s) connection from SC4SNMP to the Splunk destination. Splunk Enterprise/Cloud 8.x and or Splunk Infrastructure Monitoring (SignalFX) Splunk Enterprise/Cloud specific Requirements : - Splunk ITSI or Splunk IT Work - Ability to create a HEC token - Ability to create event and metrics indexes (or use existing) Splunk Infrastructure Monitoring specific requirements : - Ability to create or obtain real and token","title":"Requirements"},{"location":"planning/#planning-infrastructure","text":"Single installation of Splunk Connect for SNMP (SC4SNMP) on a machine with 16 Core/32 threads x64 and 12 GB ram will be able to handle up to 1300 SNMP TRAPs per sec. Single installation of Splunk Connect for SNMP (SC4SNMP) on a machine with 16 Core/32 threads x64 and 64 GB ram will be able to handle up to 1300 SNMP GETs per sec. When planning infrastructure for Splunk Connect for SNMP, (SC4SNMP) note the limitations highlighted above.","title":"Planning Infrastructure"},{"location":"gettingstarted/additional-helm-configuration/","text":"Additional HELM configuration \u00b6 deployment_values.yaml are the main point of SC4SNMP management. The most important variables are already there from the very beginning after executing: microk8s helm3 inspect values splunk - connect - for - snmp / splunk - connect - for - snmp > values . yaml The whole file is divided into the following components: scheduler splunk mib mongodb rabbitmq Shared values \u00b6 All of the components have the resources field for adjusting memory resources: resources : limits : cpu : 1000m memory : 2Gi requests : cpu : 1000m memory : 2Gi Note, that when your environment contains big amount of memory and CPU you should increase limits for all of the pods (mib, scheduler, worker, traps), as long until it works stably. More information about the concept of resources can be found in the kuberentes documentation . Scheduler, MIB and Worker contain a logLevel variable that indicates the level of logging for the pod. Scheduler values \u00b6 variable description example index indexes names, should be the same as the ones given in SCK configuration event: em_logs / metrics: em_metrics / meta: em_meta Splunk values \u00b6 variable Description Example host host address of splunk instance i-08c221389a3b9899a.ec2.splunkit.io token Splunk HTTP Event Collector token 450a69af-16a9-4f87-9628-c26f04ad3785 port port of splunk instance \u201c8088\u201d insecureSSL is insecure ssl allowed \u201ctrue\u201d clusterName name of the cluster \u201cfoo\u201d Traps values \u00b6 variable Description Example loadBalancerIP shared IP 10.0.101.22","title":"Additional HELM values"},{"location":"gettingstarted/additional-helm-configuration/#additional-helm-configuration","text":"deployment_values.yaml are the main point of SC4SNMP management. The most important variables are already there from the very beginning after executing: microk8s helm3 inspect values splunk - connect - for - snmp / splunk - connect - for - snmp > values . yaml The whole file is divided into the following components: scheduler splunk mib mongodb rabbitmq","title":"Additional HELM configuration"},{"location":"gettingstarted/additional-helm-configuration/#shared-values","text":"All of the components have the resources field for adjusting memory resources: resources : limits : cpu : 1000m memory : 2Gi requests : cpu : 1000m memory : 2Gi Note, that when your environment contains big amount of memory and CPU you should increase limits for all of the pods (mib, scheduler, worker, traps), as long until it works stably. More information about the concept of resources can be found in the kuberentes documentation . Scheduler, MIB and Worker contain a logLevel variable that indicates the level of logging for the pod.","title":"Shared values"},{"location":"gettingstarted/additional-helm-configuration/#scheduler-values","text":"variable description example index indexes names, should be the same as the ones given in SCK configuration event: em_logs / metrics: em_metrics / meta: em_meta","title":"Scheduler values"},{"location":"gettingstarted/additional-helm-configuration/#splunk-values","text":"variable Description Example host host address of splunk instance i-08c221389a3b9899a.ec2.splunkit.io token Splunk HTTP Event Collector token 450a69af-16a9-4f87-9628-c26f04ad3785 port port of splunk instance \u201c8088\u201d insecureSSL is insecure ssl allowed \u201ctrue\u201d clusterName name of the cluster \u201cfoo\u201d","title":"Splunk values"},{"location":"gettingstarted/additional-helm-configuration/#traps-values","text":"variable Description Example loadBalancerIP shared IP 10.0.101.22","title":"Traps values"},{"location":"gettingstarted/k8s-microk8s-redhat/","text":"MicroK8s installation for RHEL 8 \u00b6 Enable iSCSI API sudo yum -y update sudo setenforce 0 sudo yum install -y iscsi-initiator-utils git sudo systemctl enable iscsid Install brew and some handfull tools: /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" echo 'eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"'>> /home/ec2-user/.bash_profile eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\" brew install helm kubectl kubectx k9s nano Use kurl.sh to prepare url for a microk8s installation. Use: 1. Kubernetes version: 1.20.x ( or newer) 2. CRI: Containerd ( lates) 3. CNI: Weave (latest) 4. PVC: Provisioner openEBS (2.6.0) Url to install k8s example: curl https://kurl.sh/bb01dee | sudo bash After the installation run: echo unset KUBECONFIG >> ~/.bash_profile bash -l echo 'alias k=kubectl' >>~/.bashrc Refresh .bashrc : . ~/.bashrc Check if the installations are running: k get all -A The response for the above command should look like this: [ ec2-user@ip-172-31-16-56 ~ ] $ k get all -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system pod/coredns-74ff55c5b-lkpxc 1/1 Running 0 10m kube-system pod/coredns-74ff55c5b-sr6hl 1/1 Running 0 10m kube-system pod/etcd-ip-172-31-16-56.ec2.internal 1/1 Running 0 10m kube-system pod/kube-apiserver-ip-172-31-16-56.ec2.internal 1/1 Running 0 10m kube-system pod/kube-controller-manager-ip-172-31-16-56.ec2.internal 1/1 Running 0 10m kube-system pod/kube-proxy-spb46 1/1 Running 0 10m kube-system pod/kube-scheduler-ip-172-31-16-56.ec2.internal 1/1 Running 0 10m kube-system pod/weave-net-rkbdz 2/2 Running 1 10m NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default service/kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 11m kube-system service/kube-dns ClusterIP 10.96.0.10 <none> 53/UDP,53/TCP,9153/TCP 10m NAMESPACE NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE kube-system daemonset.apps/kube-proxy 1 1 1 1 1 kubernetes.io/os=linux 10m kube-system daemonset.apps/weave-net 1 1 1 1 1 <none> 10m NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE kube-system deployment.apps/coredns 2/2 2 2 10m NAMESPACE NAME DESIRED CURRENT READY AGE kube-system replicaset.apps/coredns-74ff55c5b 2 2 2 10m Note that you\u2019ll use helm commands with helm and not microk8s helm . Also, for SNMP install you need to create PV for mongodb and rabbitmq. To do so, please create two files: touch rabbitmq_pvc.yaml touch mongodb_pvc.yaml The content of rabbitmq_pvc.yaml should be: kind : PersistentVolume apiVersion : v1 metadata : name : pv1 labels : type : local app : app spec : capacity : storage : 15Gi accessModes : - ReadWriteOnce hostPath : path : \"/home/ec2-user/data/pv1\" The content of mongodb_pvc.yaml should be: kind : PersistentVolume apiVersion : v1 metadata : name : pv2 labels : type : local app : app spec : capacity : storage : 15Gi accessModes : - ReadWriteOnce hostPath : path : \"/home/ec2-user/data/pv2\" Where directory in hostPath.path ec2-user should refer to yours account name. Create directory trees: mkdir -p /home/ec2-user/data/pv1 /home/ec2-user/data/pv2 Where ec2-user is yours account name. Move files to directories: mv mongodb_pvc.yaml /home/ec2-user/data/pv1 mv rabbitmq_pvc.yaml /home/ec2-user/data/pv2 Change directories ownership: sudo chown -R 1001:1001 ~/data","title":"MicroK8s installation for RHEL 8"},{"location":"gettingstarted/k8s-microk8s-redhat/#microk8s-installation-for-rhel-8","text":"Enable iSCSI API sudo yum -y update sudo setenforce 0 sudo yum install -y iscsi-initiator-utils git sudo systemctl enable iscsid Install brew and some handfull tools: /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" echo 'eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\"'>> /home/ec2-user/.bash_profile eval \"$(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\" brew install helm kubectl kubectx k9s nano Use kurl.sh to prepare url for a microk8s installation. Use: 1. Kubernetes version: 1.20.x ( or newer) 2. CRI: Containerd ( lates) 3. CNI: Weave (latest) 4. PVC: Provisioner openEBS (2.6.0) Url to install k8s example: curl https://kurl.sh/bb01dee | sudo bash After the installation run: echo unset KUBECONFIG >> ~/.bash_profile bash -l echo 'alias k=kubectl' >>~/.bashrc Refresh .bashrc : . ~/.bashrc Check if the installations are running: k get all -A The response for the above command should look like this: [ ec2-user@ip-172-31-16-56 ~ ] $ k get all -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system pod/coredns-74ff55c5b-lkpxc 1/1 Running 0 10m kube-system pod/coredns-74ff55c5b-sr6hl 1/1 Running 0 10m kube-system pod/etcd-ip-172-31-16-56.ec2.internal 1/1 Running 0 10m kube-system pod/kube-apiserver-ip-172-31-16-56.ec2.internal 1/1 Running 0 10m kube-system pod/kube-controller-manager-ip-172-31-16-56.ec2.internal 1/1 Running 0 10m kube-system pod/kube-proxy-spb46 1/1 Running 0 10m kube-system pod/kube-scheduler-ip-172-31-16-56.ec2.internal 1/1 Running 0 10m kube-system pod/weave-net-rkbdz 2/2 Running 1 10m NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default service/kubernetes ClusterIP 10.96.0.1 <none> 443/TCP 11m kube-system service/kube-dns ClusterIP 10.96.0.10 <none> 53/UDP,53/TCP,9153/TCP 10m NAMESPACE NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE kube-system daemonset.apps/kube-proxy 1 1 1 1 1 kubernetes.io/os=linux 10m kube-system daemonset.apps/weave-net 1 1 1 1 1 <none> 10m NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE kube-system deployment.apps/coredns 2/2 2 2 10m NAMESPACE NAME DESIRED CURRENT READY AGE kube-system replicaset.apps/coredns-74ff55c5b 2 2 2 10m Note that you\u2019ll use helm commands with helm and not microk8s helm . Also, for SNMP install you need to create PV for mongodb and rabbitmq. To do so, please create two files: touch rabbitmq_pvc.yaml touch mongodb_pvc.yaml The content of rabbitmq_pvc.yaml should be: kind : PersistentVolume apiVersion : v1 metadata : name : pv1 labels : type : local app : app spec : capacity : storage : 15Gi accessModes : - ReadWriteOnce hostPath : path : \"/home/ec2-user/data/pv1\" The content of mongodb_pvc.yaml should be: kind : PersistentVolume apiVersion : v1 metadata : name : pv2 labels : type : local app : app spec : capacity : storage : 15Gi accessModes : - ReadWriteOnce hostPath : path : \"/home/ec2-user/data/pv2\" Where directory in hostPath.path ec2-user should refer to yours account name. Create directory trees: mkdir -p /home/ec2-user/data/pv1 /home/ec2-user/data/pv2 Where ec2-user is yours account name. Move files to directories: mv mongodb_pvc.yaml /home/ec2-user/data/pv1 mv rabbitmq_pvc.yaml /home/ec2-user/data/pv2 Change directories ownership: sudo chown -R 1001:1001 ~/data","title":"MicroK8s installation for RHEL 8"},{"location":"gettingstarted/k8s-microk8s/","text":"MicroK8s installation for CentOS and Ubuntu \u00b6 Snap tool is installed by default only on Ubuntu. If you use a different platform you need to install snap first. For CentOS: Installing snap on CentOS | Snapcraft documentation For RedHat 7: Installing snap on RedHat | Snapcraft documentation Then microk8s must be installed with: sudo snap install microk8s --classic Add user to the microk8s group to no longer have to use the sudo command sudo usermod -a -G microk8s $USER sudo chown -f -R $USER ~/.kube su - $USER Check microk8s status microk8s status --wait-ready Install required microk8s dependencies to deploy SC4SNMP. Note: when installing metallb you will be prompted for one or more IPs to use as entry points Into the cluster. If your plan to enable clustering, this IP should not be assigned to the host (floats) If you do not plan to cluster, then this IP may be the same IP as the host Note2: a single IP in cidr format is x.x.x.x/32 use CIDR or range syntax microk8s enable dns metallb rbac storage openebs helm3 Verify microk8s status microk8s status --wait-ready","title":"Install Microk8s"},{"location":"gettingstarted/k8s-microk8s/#microk8s-installation-for-centos-and-ubuntu","text":"Snap tool is installed by default only on Ubuntu. If you use a different platform you need to install snap first. For CentOS: Installing snap on CentOS | Snapcraft documentation For RedHat 7: Installing snap on RedHat | Snapcraft documentation Then microk8s must be installed with: sudo snap install microk8s --classic Add user to the microk8s group to no longer have to use the sudo command sudo usermod -a -G microk8s $USER sudo chown -f -R $USER ~/.kube su - $USER Check microk8s status microk8s status --wait-ready Install required microk8s dependencies to deploy SC4SNMP. Note: when installing metallb you will be prompted for one or more IPs to use as entry points Into the cluster. If your plan to enable clustering, this IP should not be assigned to the host (floats) If you do not plan to cluster, then this IP may be the same IP as the host Note2: a single IP in cidr format is x.x.x.x/32 use CIDR or range syntax microk8s enable dns metallb rbac storage openebs helm3 Verify microk8s status microk8s status --wait-ready","title":"MicroK8s installation for CentOS and Ubuntu"},{"location":"gettingstarted/sc4snmp-configuration/","text":"Test SNMP Traps \u00b6 Test the trap from a linux system with SNMP installed. Replace the IP address 10.0.101.22 with the shared IP address above apt-get install snmpd snmptrap -v2c -c public 10 .0.101.22 123 1 .3.6.1.6.3.1.1.5.1 1 .3.6.1.2.1.1.5.0 s test Search splunk: You should see one event per trap command with the host value of the test machine IP address index = em_logs sourcetype = \"sc4snmp:traps\" Setup Poller \u00b6 Test the poller by logging into Splunk and confirm the presence of events in snmp em_logs and metrics in em_metrics index Inventory \u00b6 * You can change the inventory contents in config_values.yaml , in scheduler inventory field, ex.: files : scheduler : inventory : | host , version , community , profile 10.0 . 101.22 , 2 c , public , basev1 10.0 . 101.23 , 2 c , public ,* Where 10.0.101.22 is a host IP. Content below is interpreted as a .csv file with the following columns: host (IP or name) version of SNMP protocol community string authorisation phrase profile of device (varBinds of profiles can be found in config.yaml, defined in scheduler config in values.yaml), for automatic profile assignment \u2018*\u2019 can be used, profile name may contain only letters, numbers, underscore or dash Config \u00b6 Profiles used in inventory can be created in config_values.yaml , which can be modified in scheduler config in values.yaml , ex.: files : scheduler : config : | celery : ... profiles : basev1 : frequency : 10 patterns : - '.*STRING_TO_BE_MATCHED.*' varBinds : # Syntax : [ \"MIB-Files\" , \"MIB object name\" \"MIB index number\" ] - [ 'SNMPv2-MIB' , 'sysDescr' ] - [ 'SNMPv2-MIB' , 'sysUpTime' , 0 ] - [ 'SNMPv2-MIB' , 'sysName' ] frequency - frequency in seconds (how often SNMP connector should ask agent for data) patterns - list of regular expressions that will be matched against sysDescr or sysObjectId Every change in values.yaml file can be applied with the command: microk8s helm3 upgrade --install snmp -f deployment_values.yaml -f config_values.yaml -f static_values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace This command should produce this kind of output: Release \"snmp\" has been upgraded. Happy Helming! NAME: snmp LAST DEPLOYED: Thu Sep 9 10:54:04 2021 NAMESPACE: sc4snmp STATUS: deployed REVISION: 2 TEST SUITE: None More information about how to configure deployment_values.yaml is available here: Additional HELM values Dynamic profile assignment \u00b6 If you want to use dynamic profile assignment please place * as profile name in inventory. sysDescr or sysObjectId from the agent will be matched against entries in patterns property of each profile. The matching process may result in multiple profiles per device. Test Poller \u00b6 Search splunk: You should see one event per trap command with the host value of the test machine IP address index = em_meta sourcetype = \"sc4snmp:meta\" SNMPv2_MIB__sysLocation_0 = \"*\" | dedup host | mcatalog values ( metric_name ) where index = em_metrics AND metric_name = sc4snmp* AND host = <hostname> Maintain \u00b6 Manage configuration, obtain and update communities, user/secrets and inventories","title":"Configure Poller and Traps"},{"location":"gettingstarted/sc4snmp-configuration/#test-snmp-traps","text":"Test the trap from a linux system with SNMP installed. Replace the IP address 10.0.101.22 with the shared IP address above apt-get install snmpd snmptrap -v2c -c public 10 .0.101.22 123 1 .3.6.1.6.3.1.1.5.1 1 .3.6.1.2.1.1.5.0 s test Search splunk: You should see one event per trap command with the host value of the test machine IP address index = em_logs sourcetype = \"sc4snmp:traps\"","title":"Test SNMP Traps"},{"location":"gettingstarted/sc4snmp-configuration/#setup-poller","text":"Test the poller by logging into Splunk and confirm the presence of events in snmp em_logs and metrics in em_metrics index","title":"Setup Poller"},{"location":"gettingstarted/sc4snmp-configuration/#inventory","text":"* You can change the inventory contents in config_values.yaml , in scheduler inventory field, ex.: files : scheduler : inventory : | host , version , community , profile 10.0 . 101.22 , 2 c , public , basev1 10.0 . 101.23 , 2 c , public ,* Where 10.0.101.22 is a host IP. Content below is interpreted as a .csv file with the following columns: host (IP or name) version of SNMP protocol community string authorisation phrase profile of device (varBinds of profiles can be found in config.yaml, defined in scheduler config in values.yaml), for automatic profile assignment \u2018*\u2019 can be used, profile name may contain only letters, numbers, underscore or dash","title":"Inventory"},{"location":"gettingstarted/sc4snmp-configuration/#config","text":"Profiles used in inventory can be created in config_values.yaml , which can be modified in scheduler config in values.yaml , ex.: files : scheduler : config : | celery : ... profiles : basev1 : frequency : 10 patterns : - '.*STRING_TO_BE_MATCHED.*' varBinds : # Syntax : [ \"MIB-Files\" , \"MIB object name\" \"MIB index number\" ] - [ 'SNMPv2-MIB' , 'sysDescr' ] - [ 'SNMPv2-MIB' , 'sysUpTime' , 0 ] - [ 'SNMPv2-MIB' , 'sysName' ] frequency - frequency in seconds (how often SNMP connector should ask agent for data) patterns - list of regular expressions that will be matched against sysDescr or sysObjectId Every change in values.yaml file can be applied with the command: microk8s helm3 upgrade --install snmp -f deployment_values.yaml -f config_values.yaml -f static_values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace This command should produce this kind of output: Release \"snmp\" has been upgraded. Happy Helming! NAME: snmp LAST DEPLOYED: Thu Sep 9 10:54:04 2021 NAMESPACE: sc4snmp STATUS: deployed REVISION: 2 TEST SUITE: None More information about how to configure deployment_values.yaml is available here: Additional HELM values","title":"Config"},{"location":"gettingstarted/sc4snmp-configuration/#dynamic-profile-assignment","text":"If you want to use dynamic profile assignment please place * as profile name in inventory. sysDescr or sysObjectId from the agent will be matched against entries in patterns property of each profile. The matching process may result in multiple profiles per device.","title":"Dynamic profile assignment"},{"location":"gettingstarted/sc4snmp-configuration/#test-poller","text":"Search splunk: You should see one event per trap command with the host value of the test machine IP address index = em_meta sourcetype = \"sc4snmp:meta\" SNMPv2_MIB__sysLocation_0 = \"*\" | dedup host | mcatalog values ( metric_name ) where index = em_metrics AND metric_name = sc4snmp* AND host = <hostname>","title":"Test Poller"},{"location":"gettingstarted/sc4snmp-configuration/#maintain","text":"Manage configuration, obtain and update communities, user/secrets and inventories","title":"Maintain"},{"location":"gettingstarted/sc4snmp-installation/","text":"SC4SNMP Helm installation \u00b6 Add SC4SNMP repository \u00b6 microk8s helm3 repo add splunk - connect - for - snmp https : // splunk . github . io / splunk - connect - for - snmp microk8s helm3 repo update Now the package should be visible in helm3 search command result: microk8s helm3 search repo snmp Example output: NAME CHART VERSION APP VERSION DESCRIPTION splunk - connect - for - snmp / splunk - connect - for - snmp 0 . 1 . 4 1 . 16 . 0 A Helm chart for SNMP Connect for SNMP Download and modify values.yaml \u00b6 curl - o ~/ values . yaml https : // raw . githubusercontent . com / splunk / splunk - connect - for - snmp / develop / charts / values . yaml . example values.yaml is being used during the installation process for configuring kubernetes values. Placeholder Description Example ###SPLUNK_HOST### host address of splunk instance \u201ci-08c221389a3b9899a.ec2.splunkit.io\u201d ###SPLUNK_PORT### port number of splunk instance \u201c8088\u201d ###SPLUNK_TOKEN### Splunk HTTP Event Collector token 450a69af-16a9-4f87-9628-c26f04ad3785 ###X.X.X.X### SHARED IP address used for SNMP Traps 10.202.18.166 Other variables to update in case you want to: variable description default splunk: protocol port of splunk instance https splunk: insecure_ssl is insecure ssl allowed \u201cfalse\u201d splunk: cluster_name name of the cluster \u201cfoo\u201d Install SC4SNMP \u00b6 microk8s helm3 install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace From now on, when editing SC4SNMP configuration, the configuration change must be inserted in the corresponding section of values.yaml . For more details check configuration section. Use the following command to propagate configuration changes: microk8s helm3 upgrade --install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace Verify deployment \u00b6 In a few minutes, all pods should be up and running. It can be verified with: microk8s kubectl get pods -n sc4snmp Example output: NAME READY STATUS RESTARTS AGE sc4snmp-scheduler-8566485657-qxzs2 1/1 Running 0 105s sc4snmp-mib-server-77d79fb469-9t4hl 1/1 Running 0 105s sc4snmp-worker-c57696f7f-dtcxf 1/1 Running 0 105s sc4snmp-otel-6b65b45b84-rh7sl 1/1 Running 0 105s sc4snmp-traps-6b8567554f-vcrvj 1/1 Running 0 105s sc4snmp-mongodb-arbiter-0 1/1 Running 0 105s sc4snmp-mongodb-0 2/2 Running 0 105s sc4snmp-mongodb-1 2/2 Running 0 35s sc4snmp-rabbitmq-0 1/1 Running 0 105s sc4snmp-rabbitmq-1 1/1 Running 0 105s","title":"Install SC4SNMP"},{"location":"gettingstarted/sc4snmp-installation/#sc4snmp-helm-installation","text":"","title":"SC4SNMP Helm installation"},{"location":"gettingstarted/sc4snmp-installation/#add-sc4snmp-repository","text":"microk8s helm3 repo add splunk - connect - for - snmp https : // splunk . github . io / splunk - connect - for - snmp microk8s helm3 repo update Now the package should be visible in helm3 search command result: microk8s helm3 search repo snmp Example output: NAME CHART VERSION APP VERSION DESCRIPTION splunk - connect - for - snmp / splunk - connect - for - snmp 0 . 1 . 4 1 . 16 . 0 A Helm chart for SNMP Connect for SNMP","title":"Add SC4SNMP repository"},{"location":"gettingstarted/sc4snmp-installation/#download-and-modify-valuesyaml","text":"curl - o ~/ values . yaml https : // raw . githubusercontent . com / splunk / splunk - connect - for - snmp / develop / charts / values . yaml . example values.yaml is being used during the installation process for configuring kubernetes values. Placeholder Description Example ###SPLUNK_HOST### host address of splunk instance \u201ci-08c221389a3b9899a.ec2.splunkit.io\u201d ###SPLUNK_PORT### port number of splunk instance \u201c8088\u201d ###SPLUNK_TOKEN### Splunk HTTP Event Collector token 450a69af-16a9-4f87-9628-c26f04ad3785 ###X.X.X.X### SHARED IP address used for SNMP Traps 10.202.18.166 Other variables to update in case you want to: variable description default splunk: protocol port of splunk instance https splunk: insecure_ssl is insecure ssl allowed \u201cfalse\u201d splunk: cluster_name name of the cluster \u201cfoo\u201d","title":"Download and modify values.yaml"},{"location":"gettingstarted/sc4snmp-installation/#install-sc4snmp","text":"microk8s helm3 install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace From now on, when editing SC4SNMP configuration, the configuration change must be inserted in the corresponding section of values.yaml . For more details check configuration section. Use the following command to propagate configuration changes: microk8s helm3 upgrade --install snmp -f values.yaml splunk-connect-for-snmp/splunk-connect-for-snmp --namespace = sc4snmp --create-namespace","title":"Install SC4SNMP"},{"location":"gettingstarted/sc4snmp-installation/#verify-deployment","text":"In a few minutes, all pods should be up and running. It can be verified with: microk8s kubectl get pods -n sc4snmp Example output: NAME READY STATUS RESTARTS AGE sc4snmp-scheduler-8566485657-qxzs2 1/1 Running 0 105s sc4snmp-mib-server-77d79fb469-9t4hl 1/1 Running 0 105s sc4snmp-worker-c57696f7f-dtcxf 1/1 Running 0 105s sc4snmp-otel-6b65b45b84-rh7sl 1/1 Running 0 105s sc4snmp-traps-6b8567554f-vcrvj 1/1 Running 0 105s sc4snmp-mongodb-arbiter-0 1/1 Running 0 105s sc4snmp-mongodb-0 2/2 Running 0 105s sc4snmp-mongodb-1 2/2 Running 0 35s sc4snmp-rabbitmq-0 1/1 Running 0 105s sc4snmp-rabbitmq-1 1/1 Running 0 105s","title":"Verify deployment"},{"location":"gettingstarted/sck-installation/","text":"SPLUNK for Kubernetes installation \u00b6 The below steps are sufficient for a SCK installation for the SC4SNMP project. In case you want to investigate more, all information about Splunk Connect for Kubernetes is available here . Instalation steps \u00b6 Add SCK repository to HELM \u00b6 microk8s helm3 repo add splunk https : // splunk . github . io / splunk - connect - for - kubernetes Create values file \u00b6 In order to connect to SPLUNK instance, you must create a sck_values.yaml file with this structure, populating variables marked with \u201c###\u201d (as described below): #global settings global : logLevel : info splunk : hec : protocol : https insecureSSL : \"false\" host : ###SPLUNK_HOST### token : ###SPLUNK_TOKEN### port : ###SPLUNK_PORT### kubernetes : clusterName : ###CLUSTER_NAME### #local config for logging chart splunk-kubernetes-logging : # Enable chart enabled : true # Determine logging level per chart logLevel : info containers : logFormatType : cri logFormat : \"%Y-%m-%dT%H:%M:%S.%N%:z\" # Filter on Namespace to reduce log noise from all namespaces fluentd : path : \"/var/log/containers/*_sc4snmp_*.log,/var/log/containers/*_sck_*.log\" kubernetes : securityContext : true # Set journald path. Update to reflect MicroK8s systemd services. See MicroK8s Docs. journalLogPath : /var/log/journal # Review flush intervals for Splunk Cloud vs Self-Managed back off timers buffer : \"@type\" : memory total_limit_size : 600m chunk_limit_size : 10m chunk_limit_records : 100000 flush_interval : 5s flush_thread_count : 1 overflow_action : block retry_max_times : 10 retry_type : periodic k8sMetadata : # Pod labels to collect podLabels : - app - k8s-app - release - environment - tier # In case snmp prefix is useful or if you want to remove \"kube\" sourcetypePrefix : \"kube\" splunk : hec : indexName : em_logs logs : sck : from : pod : sck-splunk-kubernetes- container : splunk-fluentd-k8s- multiline : firstline : /^\\d{4}-\\d{2}-\\d{2}\\s\\d{2}\\:\\d{2}\\:\\d{2}\\s\\+\\d{4}\\s\\[\\w+\\]\\:/ separator : \"\\n\" flushInterval : 5 #local config for objects chart splunk-kubernetes-objects : # enable or diable objects enabled : false rbac : create : true serviceAccount : create : true name : splunk-kubernetes-objects kubernetes : insecureSSL : true objects : core : v1 : - name : pods - name : namespaces - name : component_statuses - name : nodes - name : services - name : events mode : watch splunk : hec : indexName : em_meta #local config for metrics chart splunk-kubernetes-metrics : # enable or disbale metrics enabled : false metricsInterval : 60s kubernetes : kubeletPort : 10255 kubeletPortAggregator : 10250 useRestClientSSL : false insecureSSL : true rbac : create : true serviceAccount : create : true name : splunk-kubernetes-metrics splunk : hec : indexName : em_metrics customFilters : node : tag : \"kube.node.**\" type : record_modifier body : |- <record> entity_type k8s_node </record> pod : tag : \"kube.pod.**\" type : record_modifier body : |- <record> entity_type k8s_pod </record> Values description \u00b6 Values required to be filled: Placeholder Description Example ###SPLUNK_HOST### host address of splunk instance \u201ci-08c221389a3b9899a.ec2.splunkit.io\u201d ###SPLUNK_PORT### port number of splunk instance \u201c8088\u201d ###SPLUNK_TOKEN### Splunk HTTP Event Collector token \u201c450a69af-16a9-4f87-9628-c26f04ad3785\u201d ###CLUSTER_NAME### name of the cluster \u201cfoo\u201d In case you want to change index names (note that in this case you need to keep consistent names in Splunk instance and SC4SNMP values file), you can override these variables: Index type variable description default value Logs index splunk-kubernetes-logging: splunk: hec: indexName: name of the logs index \u201cem_index\u201d Meta index splunk-kubernetes-objects: splunk: hec: indexName: name of the meta index \u201cem_meta\u201d Metrics index splunk-kubernetes-metrics: splunk: hec: indexName: name of the metrics index \u201cem_metrics\u201d Other variables you can override, if necessary: in case you need it: variable description default global: splunk: hec: protocol port of splunk instance \u201c8088\u201d global: splunk: hec: protocol insecure_ssl is insecure ssl allowed \u201cfalse\u201d Install SCK with HELM \u00b6 microk8s helm3 install sck-for-snmp -f sck_values.yaml splunk/splunk-connect-for-kubernetes","title":"Install Splunk for Kubernetes"},{"location":"gettingstarted/sck-installation/#splunk-for-kubernetes-installation","text":"The below steps are sufficient for a SCK installation for the SC4SNMP project. In case you want to investigate more, all information about Splunk Connect for Kubernetes is available here .","title":"SPLUNK for Kubernetes installation"},{"location":"gettingstarted/sck-installation/#instalation-steps","text":"","title":"Instalation steps"},{"location":"gettingstarted/sck-installation/#add-sck-repository-to-helm","text":"microk8s helm3 repo add splunk https : // splunk . github . io / splunk - connect - for - kubernetes","title":"Add SCK repository to HELM"},{"location":"gettingstarted/sck-installation/#create-values-file","text":"In order to connect to SPLUNK instance, you must create a sck_values.yaml file with this structure, populating variables marked with \u201c###\u201d (as described below): #global settings global : logLevel : info splunk : hec : protocol : https insecureSSL : \"false\" host : ###SPLUNK_HOST### token : ###SPLUNK_TOKEN### port : ###SPLUNK_PORT### kubernetes : clusterName : ###CLUSTER_NAME### #local config for logging chart splunk-kubernetes-logging : # Enable chart enabled : true # Determine logging level per chart logLevel : info containers : logFormatType : cri logFormat : \"%Y-%m-%dT%H:%M:%S.%N%:z\" # Filter on Namespace to reduce log noise from all namespaces fluentd : path : \"/var/log/containers/*_sc4snmp_*.log,/var/log/containers/*_sck_*.log\" kubernetes : securityContext : true # Set journald path. Update to reflect MicroK8s systemd services. See MicroK8s Docs. journalLogPath : /var/log/journal # Review flush intervals for Splunk Cloud vs Self-Managed back off timers buffer : \"@type\" : memory total_limit_size : 600m chunk_limit_size : 10m chunk_limit_records : 100000 flush_interval : 5s flush_thread_count : 1 overflow_action : block retry_max_times : 10 retry_type : periodic k8sMetadata : # Pod labels to collect podLabels : - app - k8s-app - release - environment - tier # In case snmp prefix is useful or if you want to remove \"kube\" sourcetypePrefix : \"kube\" splunk : hec : indexName : em_logs logs : sck : from : pod : sck-splunk-kubernetes- container : splunk-fluentd-k8s- multiline : firstline : /^\\d{4}-\\d{2}-\\d{2}\\s\\d{2}\\:\\d{2}\\:\\d{2}\\s\\+\\d{4}\\s\\[\\w+\\]\\:/ separator : \"\\n\" flushInterval : 5 #local config for objects chart splunk-kubernetes-objects : # enable or diable objects enabled : false rbac : create : true serviceAccount : create : true name : splunk-kubernetes-objects kubernetes : insecureSSL : true objects : core : v1 : - name : pods - name : namespaces - name : component_statuses - name : nodes - name : services - name : events mode : watch splunk : hec : indexName : em_meta #local config for metrics chart splunk-kubernetes-metrics : # enable or disbale metrics enabled : false metricsInterval : 60s kubernetes : kubeletPort : 10255 kubeletPortAggregator : 10250 useRestClientSSL : false insecureSSL : true rbac : create : true serviceAccount : create : true name : splunk-kubernetes-metrics splunk : hec : indexName : em_metrics customFilters : node : tag : \"kube.node.**\" type : record_modifier body : |- <record> entity_type k8s_node </record> pod : tag : \"kube.pod.**\" type : record_modifier body : |- <record> entity_type k8s_pod </record>","title":"Create values file"},{"location":"gettingstarted/sck-installation/#values-description","text":"Values required to be filled: Placeholder Description Example ###SPLUNK_HOST### host address of splunk instance \u201ci-08c221389a3b9899a.ec2.splunkit.io\u201d ###SPLUNK_PORT### port number of splunk instance \u201c8088\u201d ###SPLUNK_TOKEN### Splunk HTTP Event Collector token \u201c450a69af-16a9-4f87-9628-c26f04ad3785\u201d ###CLUSTER_NAME### name of the cluster \u201cfoo\u201d In case you want to change index names (note that in this case you need to keep consistent names in Splunk instance and SC4SNMP values file), you can override these variables: Index type variable description default value Logs index splunk-kubernetes-logging: splunk: hec: indexName: name of the logs index \u201cem_index\u201d Meta index splunk-kubernetes-objects: splunk: hec: indexName: name of the meta index \u201cem_meta\u201d Metrics index splunk-kubernetes-metrics: splunk: hec: indexName: name of the metrics index \u201cem_metrics\u201d Other variables you can override, if necessary: in case you need it: variable description default global: splunk: hec: protocol port of splunk instance \u201c8088\u201d global: splunk: hec: protocol insecure_ssl is insecure ssl allowed \u201cfalse\u201d","title":"Values description"},{"location":"gettingstarted/sck-installation/#install-sck-with-helm","text":"microk8s helm3 install sck-for-snmp -f sck_values.yaml splunk/splunk-connect-for-kubernetes","title":"Install SCK with HELM"},{"location":"gettingstarted/splunk-requirements/","text":"Splunk requirements \u00b6 Prepare Splunk \u00b6 Requirements (Splunk Enterprise/Enterprise Cloud) \u00b6 Complete the installation of Splunk IT Essentials Work OR Splunk IT Service Intelligence Verify the creation of the following indexes: em_metrics (metrics type) em_meta (event type) em_logs (event type) Create or obtain a new Splunk HTTP Event Collector token and the correct https endpoint. Verify the token using curl Note: The endpoint must use a publicly trusted certificate authority. The SHARED IP address to be used for SNMP Traps. Note Simple and POC deployments will use the same IP as the host server. If HA deployment will be used, the IP must be in addition to the managment interface of each cluster member. Obtain the ip address of an internal DNS server that is able to resolve the Splunk Endpoint. Requirements (Splunk Infrastructure Monitoring) \u00b6 Obtain the correct realm and token.","title":"Splunk Requirements"},{"location":"gettingstarted/splunk-requirements/#splunk-requirements","text":"","title":"Splunk requirements"},{"location":"gettingstarted/splunk-requirements/#prepare-splunk","text":"","title":"Prepare Splunk"},{"location":"gettingstarted/splunk-requirements/#requirements-splunk-enterpriseenterprise-cloud","text":"Complete the installation of Splunk IT Essentials Work OR Splunk IT Service Intelligence Verify the creation of the following indexes: em_metrics (metrics type) em_meta (event type) em_logs (event type) Create or obtain a new Splunk HTTP Event Collector token and the correct https endpoint. Verify the token using curl Note: The endpoint must use a publicly trusted certificate authority. The SHARED IP address to be used for SNMP Traps. Note Simple and POC deployments will use the same IP as the host server. If HA deployment will be used, the IP must be in addition to the managment interface of each cluster member. Obtain the ip address of an internal DNS server that is able to resolve the Splunk Endpoint.","title":"Requirements (Splunk Enterprise/Enterprise Cloud)"},{"location":"gettingstarted/splunk-requirements/#requirements-splunk-infrastructure-monitoring","text":"Obtain the correct realm and token.","title":"Requirements (Splunk Infrastructure Monitoring)"}]}